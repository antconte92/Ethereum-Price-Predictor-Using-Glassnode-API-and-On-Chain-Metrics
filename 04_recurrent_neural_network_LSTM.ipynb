{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (RNN) - ETH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/eth_api_data_use.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('t', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sending_count</th>\n",
       "      <th>receiving_count</th>\n",
       "      <th>active_count</th>\n",
       "      <th>new_non_zero_count</th>\n",
       "      <th>block_height</th>\n",
       "      <th>sopr</th>\n",
       "      <th>price_usd_close</th>\n",
       "      <th>marketcap_usd</th>\n",
       "      <th>difficulty_latest</th>\n",
       "      <th>hash_rate_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-08</th>\n",
       "      <td>10641</td>\n",
       "      <td>582</td>\n",
       "      <td>439</td>\n",
       "      <td>800</td>\n",
       "      <td>353</td>\n",
       "      <td>55869</td>\n",
       "      <td>0.459823</td>\n",
       "      <td>0.769981</td>\n",
       "      <td>8.983510e+07</td>\n",
       "      <td>1606016380751</td>\n",
       "      <td>9.644985e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-09</th>\n",
       "      <td>10894</td>\n",
       "      <td>457</td>\n",
       "      <td>489</td>\n",
       "      <td>731</td>\n",
       "      <td>253</td>\n",
       "      <td>60992</td>\n",
       "      <td>0.403942</td>\n",
       "      <td>0.719830</td>\n",
       "      <td>5.507245e+07</td>\n",
       "      <td>1741399466631</td>\n",
       "      <td>1.013969e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>11543</td>\n",
       "      <td>804</td>\n",
       "      <td>749</td>\n",
       "      <td>997</td>\n",
       "      <td>649</td>\n",
       "      <td>66247</td>\n",
       "      <td>0.360587</td>\n",
       "      <td>0.700705</td>\n",
       "      <td>4.878861e+07</td>\n",
       "      <td>1948102094734</td>\n",
       "      <td>1.116431e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>13432</td>\n",
       "      <td>2119</td>\n",
       "      <td>2106</td>\n",
       "      <td>2339</td>\n",
       "      <td>1889</td>\n",
       "      <td>71527</td>\n",
       "      <td>0.614763</td>\n",
       "      <td>1.088361</td>\n",
       "      <td>5.745360e+07</td>\n",
       "      <td>2171897473895</td>\n",
       "      <td>1.240757e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-12</th>\n",
       "      <td>13744</td>\n",
       "      <td>565</td>\n",
       "      <td>673</td>\n",
       "      <td>904</td>\n",
       "      <td>312</td>\n",
       "      <td>76651</td>\n",
       "      <td>0.609176</td>\n",
       "      <td>1.214071</td>\n",
       "      <td>8.079017e+07</td>\n",
       "      <td>2248237602936</td>\n",
       "      <td>1.308930e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-29</th>\n",
       "      <td>126646738</td>\n",
       "      <td>216340</td>\n",
       "      <td>261453</td>\n",
       "      <td>443638</td>\n",
       "      <td>81015</td>\n",
       "      <td>13123511</td>\n",
       "      <td>1.038184</td>\n",
       "      <td>3232.684457</td>\n",
       "      <td>3.771270e+11</td>\n",
       "      <td>8344135842611030</td>\n",
       "      <td>6.156244e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>126736492</td>\n",
       "      <td>216528</td>\n",
       "      <td>279101</td>\n",
       "      <td>463898</td>\n",
       "      <td>89754</td>\n",
       "      <td>13129983</td>\n",
       "      <td>1.054713</td>\n",
       "      <td>3236.705129</td>\n",
       "      <td>3.779495e+11</td>\n",
       "      <td>8363391489903990</td>\n",
       "      <td>6.243794e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>126832691</td>\n",
       "      <td>232263</td>\n",
       "      <td>294382</td>\n",
       "      <td>489456</td>\n",
       "      <td>96199</td>\n",
       "      <td>13136426</td>\n",
       "      <td>1.068187</td>\n",
       "      <td>3440.253672</td>\n",
       "      <td>3.918475e+11</td>\n",
       "      <td>8409844260273910</td>\n",
       "      <td>6.290792e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>126936884</td>\n",
       "      <td>233412</td>\n",
       "      <td>306440</td>\n",
       "      <td>505920</td>\n",
       "      <td>104193</td>\n",
       "      <td>13142881</td>\n",
       "      <td>1.114021</td>\n",
       "      <td>3799.940179</td>\n",
       "      <td>4.195039e+11</td>\n",
       "      <td>8261844770140400</td>\n",
       "      <td>6.207080e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>127045785</td>\n",
       "      <td>243246</td>\n",
       "      <td>309822</td>\n",
       "      <td>518096</td>\n",
       "      <td>108901</td>\n",
       "      <td>13149422</td>\n",
       "      <td>1.093690</td>\n",
       "      <td>3792.519107</td>\n",
       "      <td>4.428463e+11</td>\n",
       "      <td>8728753920436170</td>\n",
       "      <td>6.449494e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2214 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                count  sending_count  receiving_count  active_count  \\\n",
       "t                                                                     \n",
       "2015-08-08      10641            582              439           800   \n",
       "2015-08-09      10894            457              489           731   \n",
       "2015-08-10      11543            804              749           997   \n",
       "2015-08-11      13432           2119             2106          2339   \n",
       "2015-08-12      13744            565              673           904   \n",
       "...               ...            ...              ...           ...   \n",
       "2021-08-29  126646738         216340           261453        443638   \n",
       "2021-08-30  126736492         216528           279101        463898   \n",
       "2021-08-31  126832691         232263           294382        489456   \n",
       "2021-09-01  126936884         233412           306440        505920   \n",
       "2021-09-02  127045785         243246           309822        518096   \n",
       "\n",
       "            new_non_zero_count  block_height      sopr  price_usd_close  \\\n",
       "t                                                                         \n",
       "2015-08-08                 353         55869  0.459823         0.769981   \n",
       "2015-08-09                 253         60992  0.403942         0.719830   \n",
       "2015-08-10                 649         66247  0.360587         0.700705   \n",
       "2015-08-11                1889         71527  0.614763         1.088361   \n",
       "2015-08-12                 312         76651  0.609176         1.214071   \n",
       "...                        ...           ...       ...              ...   \n",
       "2021-08-29               81015      13123511  1.038184      3232.684457   \n",
       "2021-08-30               89754      13129983  1.054713      3236.705129   \n",
       "2021-08-31               96199      13136426  1.068187      3440.253672   \n",
       "2021-09-01              104193      13142881  1.114021      3799.940179   \n",
       "2021-09-02              108901      13149422  1.093690      3792.519107   \n",
       "\n",
       "            marketcap_usd  difficulty_latest  hash_rate_mean  \n",
       "t                                                             \n",
       "2015-08-08   8.983510e+07      1606016380751    9.644985e+10  \n",
       "2015-08-09   5.507245e+07      1741399466631    1.013969e+11  \n",
       "2015-08-10   4.878861e+07      1948102094734    1.116431e+11  \n",
       "2015-08-11   5.745360e+07      2171897473895    1.240757e+11  \n",
       "2015-08-12   8.079017e+07      2248237602936    1.308930e+11  \n",
       "...                   ...                ...             ...  \n",
       "2021-08-29   3.771270e+11   8344135842611030    6.156244e+14  \n",
       "2021-08-30   3.779495e+11   8363391489903990    6.243794e+14  \n",
       "2021-08-31   3.918475e+11   8409844260273910    6.290792e+14  \n",
       "2021-09-01   4.195039e+11   8261844770140400    6.207080e+14  \n",
       "2021-09-02   4.428463e+11   8728753920436170    6.449494e+14  \n",
       "\n",
       "[2214 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2214 entries, 2015-08-08 to 2021-09-02\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   count               2214 non-null   int64  \n",
      " 1   sending_count       2214 non-null   int64  \n",
      " 2   receiving_count     2214 non-null   int64  \n",
      " 3   active_count        2214 non-null   int64  \n",
      " 4   new_non_zero_count  2214 non-null   int64  \n",
      " 5   block_height        2214 non-null   int64  \n",
      " 6   sopr                2214 non-null   float64\n",
      " 7   price_usd_close     2214 non-null   float64\n",
      " 8   marketcap_usd       2214 non-null   float64\n",
      " 9   difficulty_latest   2214 non-null   int64  \n",
      " 10  hash_rate_mean      2214 non-null   float64\n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 207.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproccesing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['price_usd_close'].plot(figsize=(15,7), title='ETH Closing Prices');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing/Scaling the Data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2214 entries, 2015-08-08 to 2021-09-02\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   count               2214 non-null   float64\n",
      " 1   sending_count       2214 non-null   float64\n",
      " 2   receiving_count     2214 non-null   float64\n",
      " 3   active_count        2214 non-null   float64\n",
      " 4   new_non_zero_count  2214 non-null   float64\n",
      " 5   block_height        2214 non-null   float64\n",
      " 6   sopr                2214 non-null   float64\n",
      " 7   price_usd_close     2214 non-null   float64\n",
      " 8   marketcap_usd       2214 non-null   float64\n",
      " 9   difficulty_latest   2214 non-null   float64\n",
      " 10  hash_rate_mean      2214 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 207.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Preparing LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(seq, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Splits the univariate time sequence\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        end = i + n_steps_in\n",
    "        out_end = end + n_steps_out\n",
    "        \n",
    "        if out_end > len(seq):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = seq[i:end], seq[end:out_end]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    \"\"\"\n",
    "    Plots the loss and accuracy for the training and testing data\n",
    "    \"\"\"\n",
    "    history = results.history\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_maker(n_layers, n_nodes, activation, drop=None, d_rate=.5):\n",
    "    \"\"\"\n",
    "    Creates a specified number of hidden layers for an RNN\n",
    "    Optional: Adds regularization option - the dropout layer to prevent potential overfitting (if necessary)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating the specified number of hidden layers with the specified number of nodes\n",
    "    for x in range(1,n_layers+1):\n",
    "        model.add(LSTM(n_nodes, activation=activation, return_sequences=True))\n",
    "\n",
    "        # Adds a Dropout layer after every Nth hidden layer (the 'drop' variable)\n",
    "        try:\n",
    "            if x % drop == 0:\n",
    "                model.add(Dropout(d_rate))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many periods looking back to learn\n",
    "n_per_in  = 90\n",
    "\n",
    "# How many periods to predict\n",
    "n_per_out = 30\n",
    "\n",
    "# Features (in this case it's 1 because there is only one feature: price)\n",
    "n_features = 1\n",
    "\n",
    "# Splitting the data into appropriate sequences\n",
    "X, y = split_sequence(list(df.price_usd_close), n_per_in, n_per_out)\n",
    "\n",
    "# Reshaping the X variable from 2D to 3D\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - LSTM (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 90, 30)            3840      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 90, 12)            2064      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 90, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 90, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 90, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 90, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 90, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 10)                920       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                330       \n",
      "=================================================================\n",
      "Total params: 13,154\n",
      "Trainable params: 13,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instatiating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Activation\n",
    "activ = \"softsign\"\n",
    "\n",
    "# Input layer\n",
    "model.add(LSTM(30, activation=activ, return_sequences=True, input_shape=(n_per_in, n_features)))\n",
    "\n",
    "# Hidden layers\n",
    "layer_maker(n_layers=6, n_nodes=12, activation=activ)\n",
    "\n",
    "# Final Hidden layer\n",
    "model.add(LSTM(10, activation=activ))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(n_per_out))\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the data with selected specifications\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "59/59 [==============================] - 14s 231ms/step - loss: 0.0042 - accuracy: 0.0249 - val_loss: 0.2242 - val_accuracy: 0.0190\n",
      "Epoch 2/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 0.0016 - accuracy: 0.0265 - val_loss: 0.1631 - val_accuracy: 0.0190\n",
      "Epoch 3/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 0.0012 - accuracy: 0.0260 - val_loss: 0.1478 - val_accuracy: 0.0333\n",
      "Epoch 4/800\n",
      "59/59 [==============================] - 15s 246ms/step - loss: 0.0010 - accuracy: 0.0255 - val_loss: 0.1436 - val_accuracy: 0.0333\n",
      "Epoch 5/800\n",
      "59/59 [==============================] - 14s 242ms/step - loss: 0.0010 - accuracy: 0.0398 - val_loss: 0.1486 - val_accuracy: 0.0333\n",
      "Epoch 6/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 9.7578e-04 - accuracy: 0.0584 - val_loss: 0.1360 - val_accuracy: 0.0238\n",
      "Epoch 7/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 8.8176e-04 - accuracy: 0.0377 - val_loss: 0.1222 - val_accuracy: 0.0333\n",
      "Epoch 8/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 7.4718e-04 - accuracy: 0.0355 - val_loss: 0.1079 - val_accuracy: 0.0238\n",
      "Epoch 9/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 7.4465e-04 - accuracy: 0.0493 - val_loss: 0.1110 - val_accuracy: 0.0333\n",
      "Epoch 10/800\n",
      "59/59 [==============================] - 14s 231ms/step - loss: 6.8068e-04 - accuracy: 0.0403 - val_loss: 0.1133 - val_accuracy: 0.0238\n",
      "Epoch 11/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 6.4296e-04 - accuracy: 0.0456 - val_loss: 0.1124 - val_accuracy: 0.0143\n",
      "Epoch 12/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 6.4301e-04 - accuracy: 0.0557 - val_loss: 0.1149 - val_accuracy: 0.0429\n",
      "Epoch 13/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 6.3216e-04 - accuracy: 0.0499 - val_loss: 0.1180 - val_accuracy: 0.0143\n",
      "Epoch 14/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 5.9852e-04 - accuracy: 0.0504 - val_loss: 0.1338 - val_accuracy: 0.0238\n",
      "Epoch 15/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 5.5624e-04 - accuracy: 0.0499 - val_loss: 0.1362 - val_accuracy: 0.0381\n",
      "Epoch 16/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 5.6534e-04 - accuracy: 0.0531 - val_loss: 0.1374 - val_accuracy: 0.0286\n",
      "Epoch 17/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 5.3820e-04 - accuracy: 0.0488 - val_loss: 0.1515 - val_accuracy: 0.0381\n",
      "Epoch 18/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 5.7163e-04 - accuracy: 0.0573 - val_loss: 0.1692 - val_accuracy: 0.0333\n",
      "Epoch 19/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 5.1560e-04 - accuracy: 0.0424 - val_loss: 0.1484 - val_accuracy: 0.0524\n",
      "Epoch 20/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 4.7494e-04 - accuracy: 0.0546 - val_loss: 0.1666 - val_accuracy: 0.0762\n",
      "Epoch 21/800\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 4.8047e-04 - accuracy: 0.0329 - val_loss: 0.1551 - val_accuracy: 0.0714\n",
      "Epoch 22/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 4.6211e-04 - accuracy: 0.0515 - val_loss: 0.1708 - val_accuracy: 0.0476\n",
      "Epoch 23/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 4.7450e-04 - accuracy: 0.0440 - val_loss: 0.1674 - val_accuracy: 0.0476\n",
      "Epoch 24/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 4.6198e-04 - accuracy: 0.0520 - val_loss: 0.1618 - val_accuracy: 0.0571\n",
      "Epoch 25/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 4.6531e-04 - accuracy: 0.0483 - val_loss: 0.1632 - val_accuracy: 0.0476\n",
      "Epoch 26/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 4.5759e-04 - accuracy: 0.0355 - val_loss: 0.1603 - val_accuracy: 0.0429\n",
      "Epoch 27/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 4.3221e-04 - accuracy: 0.0424 - val_loss: 0.1645 - val_accuracy: 0.0476\n",
      "Epoch 28/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 4.4579e-04 - accuracy: 0.0419 - val_loss: 0.1714 - val_accuracy: 0.0571\n",
      "Epoch 29/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 4.5418e-04 - accuracy: 0.0493 - val_loss: 0.1646 - val_accuracy: 0.0381\n",
      "Epoch 30/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 4.4219e-04 - accuracy: 0.0451 - val_loss: 0.1580 - val_accuracy: 0.0238\n",
      "Epoch 31/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 5.6295e-04 - accuracy: 0.0419 - val_loss: 0.1236 - val_accuracy: 0.0905\n",
      "Epoch 32/800\n",
      "59/59 [==============================] - 14s 242ms/step - loss: 4.6179e-04 - accuracy: 0.0393 - val_loss: 0.1640 - val_accuracy: 0.0238\n",
      "Epoch 33/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 4.9593e-04 - accuracy: 0.0477 - val_loss: 0.1193 - val_accuracy: 0.0952\n",
      "Epoch 34/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 4.3096e-04 - accuracy: 0.0562 - val_loss: 0.1288 - val_accuracy: 0.0762\n",
      "Epoch 35/800\n",
      "59/59 [==============================] - 15s 255ms/step - loss: 4.1352e-04 - accuracy: 0.0594 - val_loss: 0.1391 - val_accuracy: 0.0286\n",
      "Epoch 36/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.9580e-04 - accuracy: 0.0679 - val_loss: 0.1128 - val_accuracy: 0.0810\n",
      "Epoch 37/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 3.8147e-04 - accuracy: 0.0509 - val_loss: 0.1050 - val_accuracy: 0.0667\n",
      "Epoch 38/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 4.0241e-04 - accuracy: 0.0594 - val_loss: 0.1069 - val_accuracy: 0.0667\n",
      "Epoch 39/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 3.9215e-04 - accuracy: 0.0631 - val_loss: 0.1342 - val_accuracy: 0.0333\n",
      "Epoch 40/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 3.8599e-04 - accuracy: 0.0419 - val_loss: 0.1272 - val_accuracy: 0.0286\n",
      "Epoch 41/800\n",
      "59/59 [==============================] - 19s 315ms/step - loss: 3.7995e-04 - accuracy: 0.0769 - val_loss: 0.1203 - val_accuracy: 0.0667\n",
      "Epoch 42/800\n",
      "59/59 [==============================] - 16s 270ms/step - loss: 3.5652e-04 - accuracy: 0.0541 - val_loss: 0.1233 - val_accuracy: 0.0333\n",
      "Epoch 43/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 3.4840e-04 - accuracy: 0.0711 - val_loss: 0.1275 - val_accuracy: 0.0333\n",
      "Epoch 44/800\n",
      "59/59 [==============================] - 17s 284ms/step - loss: 3.4370e-04 - accuracy: 0.0780 - val_loss: 0.1220 - val_accuracy: 0.0286\n",
      "Epoch 45/800\n",
      "59/59 [==============================] - 16s 274ms/step - loss: 3.2486e-04 - accuracy: 0.0748 - val_loss: 0.1257 - val_accuracy: 0.0381\n",
      "Epoch 46/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 3.5691e-04 - accuracy: 0.0812 - val_loss: 0.1372 - val_accuracy: 0.0238\n",
      "Epoch 47/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 3.5054e-04 - accuracy: 0.0796 - val_loss: 0.1434 - val_accuracy: 0.0333\n",
      "Epoch 48/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.3308e-04 - accuracy: 0.0854 - val_loss: 0.1340 - val_accuracy: 0.0381\n",
      "Epoch 49/800\n",
      "59/59 [==============================] - 15s 249ms/step - loss: 3.1094e-04 - accuracy: 0.0960 - val_loss: 0.1348 - val_accuracy: 0.0333\n",
      "Epoch 50/800\n",
      "59/59 [==============================] - 13s 227ms/step - loss: 3.3656e-04 - accuracy: 0.0881 - val_loss: 0.1259 - val_accuracy: 0.0286\n",
      "Epoch 51/800\n",
      "59/59 [==============================] - 14s 240ms/step - loss: 3.0594e-04 - accuracy: 0.0828 - val_loss: 0.1270 - val_accuracy: 0.0238\n",
      "Epoch 52/800\n",
      "59/59 [==============================] - 15s 256ms/step - loss: 2.8673e-04 - accuracy: 0.0960 - val_loss: 0.1366 - val_accuracy: 0.0238\n",
      "Epoch 53/800\n",
      "59/59 [==============================] - 17s 285ms/step - loss: 3.1598e-04 - accuracy: 0.0764 - val_loss: 0.1341 - val_accuracy: 0.0190\n",
      "Epoch 54/800\n",
      "59/59 [==============================] - 12s 212ms/step - loss: 2.7791e-04 - accuracy: 0.0875 - val_loss: 0.1171 - val_accuracy: 0.0238\n",
      "Epoch 55/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 3.0306e-04 - accuracy: 0.0976 - val_loss: 0.1210 - val_accuracy: 0.0190\n",
      "Epoch 56/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.1431e-04 - accuracy: 0.1082 - val_loss: 0.1518 - val_accuracy: 0.0238\n",
      "Epoch 57/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 3.1870e-04 - accuracy: 0.0907 - val_loss: 0.1284 - val_accuracy: 0.0238\n",
      "Epoch 58/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.2947e-04 - accuracy: 0.0891 - val_loss: 0.1352 - val_accuracy: 0.0476\n",
      "Epoch 59/800\n",
      "59/59 [==============================] - 12s 210ms/step - loss: 3.1012e-04 - accuracy: 0.0822 - val_loss: 0.1279 - val_accuracy: 0.0381\n",
      "Epoch 60/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.7231e-04 - accuracy: 0.0785 - val_loss: 0.1333 - val_accuracy: 0.0238\n",
      "Epoch 61/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.6440e-04 - accuracy: 0.0886 - val_loss: 0.1280 - val_accuracy: 0.0286\n",
      "Epoch 62/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 3.0022e-04 - accuracy: 0.0870 - val_loss: 0.1382 - val_accuracy: 0.0476\n",
      "Epoch 63/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.7751e-04 - accuracy: 0.0960 - val_loss: 0.1296 - val_accuracy: 0.0238\n",
      "Epoch 64/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 2.6608e-04 - accuracy: 0.0780 - val_loss: 0.1353 - val_accuracy: 0.0190\n",
      "Epoch 65/800\n",
      "59/59 [==============================] - 21s 348ms/step - loss: 2.5163e-04 - accuracy: 0.0775 - val_loss: 0.1322 - val_accuracy: 0.0286\n",
      "Epoch 66/800\n",
      "59/59 [==============================] - 16s 272ms/step - loss: 2.4448e-04 - accuracy: 0.0849 - val_loss: 0.1306 - val_accuracy: 0.0190\n",
      "Epoch 67/800\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 2.6406e-04 - accuracy: 0.0780 - val_loss: 0.1317 - val_accuracy: 0.0333\n",
      "Epoch 68/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 2.5930e-04 - accuracy: 0.1056 - val_loss: 0.1315 - val_accuracy: 0.0286\n",
      "Epoch 69/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 2.5222e-04 - accuracy: 0.0833 - val_loss: 0.1330 - val_accuracy: 0.0238\n",
      "Epoch 70/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 2.6158e-04 - accuracy: 0.0859 - val_loss: 0.1320 - val_accuracy: 0.0286\n",
      "Epoch 71/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 2.4080e-04 - accuracy: 0.0769 - val_loss: 0.1337 - val_accuracy: 0.0667\n",
      "Epoch 72/800\n",
      "59/59 [==============================] - 15s 257ms/step - loss: 3.2252e-04 - accuracy: 0.0981 - val_loss: 0.1229 - val_accuracy: 0.0429\n",
      "Epoch 73/800\n",
      "59/59 [==============================] - 15s 253ms/step - loss: 2.4316e-04 - accuracy: 0.0796 - val_loss: 0.1350 - val_accuracy: 0.0810\n",
      "Epoch 74/800\n",
      "59/59 [==============================] - 15s 253ms/step - loss: 2.4904e-04 - accuracy: 0.0886 - val_loss: 0.1324 - val_accuracy: 0.0238\n",
      "Epoch 75/800\n",
      "59/59 [==============================] - 16s 275ms/step - loss: 2.3320e-04 - accuracy: 0.0785 - val_loss: 0.1288 - val_accuracy: 0.0286\n",
      "Epoch 76/800\n",
      "59/59 [==============================] - 14s 237ms/step - loss: 2.4259e-04 - accuracy: 0.1019 - val_loss: 0.1322 - val_accuracy: 0.0476\n",
      "Epoch 77/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 2.2426e-04 - accuracy: 0.0897 - val_loss: 0.1294 - val_accuracy: 0.0667\n",
      "Epoch 78/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 2.3857e-04 - accuracy: 0.0859 - val_loss: 0.1318 - val_accuracy: 0.0286\n",
      "Epoch 79/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 2.2007e-04 - accuracy: 0.0902 - val_loss: 0.1319 - val_accuracy: 0.0476\n",
      "Epoch 80/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 2.3446e-04 - accuracy: 0.0727 - val_loss: 0.1327 - val_accuracy: 0.0524\n",
      "Epoch 81/800\n",
      "59/59 [==============================] - 13s 227ms/step - loss: 2.2173e-04 - accuracy: 0.0822 - val_loss: 0.1304 - val_accuracy: 0.0333\n",
      "Epoch 82/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 2.3435e-04 - accuracy: 0.0854 - val_loss: 0.1354 - val_accuracy: 0.0524\n",
      "Epoch 83/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 2.1727e-04 - accuracy: 0.0753 - val_loss: 0.1292 - val_accuracy: 0.0238\n",
      "Epoch 84/800\n",
      "59/59 [==============================] - 14s 240ms/step - loss: 2.0306e-04 - accuracy: 0.0923 - val_loss: 0.1354 - val_accuracy: 0.0619\n",
      "Epoch 85/800\n",
      "59/59 [==============================] - 17s 285ms/step - loss: 2.2310e-04 - accuracy: 0.0822 - val_loss: 0.1363 - val_accuracy: 0.0238\n",
      "Epoch 86/800\n",
      "59/59 [==============================] - 15s 250ms/step - loss: 2.0224e-04 - accuracy: 0.0865 - val_loss: 0.1310 - val_accuracy: 0.0381\n",
      "Epoch 87/800\n",
      "59/59 [==============================] - 14s 239ms/step - loss: 2.0185e-04 - accuracy: 0.0828 - val_loss: 0.1330 - val_accuracy: 0.0190\n",
      "Epoch 88/800\n",
      "59/59 [==============================] - 14s 237ms/step - loss: 1.9785e-04 - accuracy: 0.0886 - val_loss: 0.1328 - val_accuracy: 0.0190\n",
      "Epoch 89/800\n",
      "59/59 [==============================] - 16s 267ms/step - loss: 1.9400e-04 - accuracy: 0.0769 - val_loss: 0.1339 - val_accuracy: 0.0190\n",
      "Epoch 90/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 2.0295e-04 - accuracy: 0.0775 - val_loss: 0.1337 - val_accuracy: 0.0333\n",
      "Epoch 91/800\n",
      "59/59 [==============================] - 16s 268ms/step - loss: 2.0008e-04 - accuracy: 0.0753 - val_loss: 0.1402 - val_accuracy: 0.0619\n",
      "Epoch 92/800\n",
      "59/59 [==============================] - 16s 266ms/step - loss: 1.8314e-04 - accuracy: 0.0748 - val_loss: 0.1327 - val_accuracy: 0.0429\n",
      "Epoch 93/800\n",
      "59/59 [==============================] - 14s 242ms/step - loss: 1.8365e-04 - accuracy: 0.0721 - val_loss: 0.1295 - val_accuracy: 0.0524\n",
      "Epoch 94/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 1.7003e-04 - accuracy: 0.0796 - val_loss: 0.1348 - val_accuracy: 0.0571\n",
      "Epoch 95/800\n",
      "59/59 [==============================] - 14s 237ms/step - loss: 1.7551e-04 - accuracy: 0.0743 - val_loss: 0.1367 - val_accuracy: 0.0238\n",
      "Epoch 96/800\n",
      "59/59 [==============================] - 15s 251ms/step - loss: 1.8995e-04 - accuracy: 0.0690 - val_loss: 0.1262 - val_accuracy: 0.0238\n",
      "Epoch 97/800\n",
      "59/59 [==============================] - 14s 237ms/step - loss: 1.7254e-04 - accuracy: 0.0721 - val_loss: 0.1317 - val_accuracy: 0.0381\n",
      "Epoch 98/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 1.6752e-04 - accuracy: 0.0748 - val_loss: 0.1312 - val_accuracy: 0.0571\n",
      "Epoch 99/800\n",
      "59/59 [==============================] - 13s 225ms/step - loss: 1.7153e-04 - accuracy: 0.0721 - val_loss: 0.1355 - val_accuracy: 0.0619\n",
      "Epoch 100/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 1.7041e-04 - accuracy: 0.0706 - val_loss: 0.1317 - val_accuracy: 0.0429\n",
      "Epoch 101/800\n",
      "59/59 [==============================] - 15s 257ms/step - loss: 1.7028e-04 - accuracy: 0.0817 - val_loss: 0.1305 - val_accuracy: 0.0571\n",
      "Epoch 102/800\n",
      "59/59 [==============================] - 15s 260ms/step - loss: 1.6039e-04 - accuracy: 0.0801 - val_loss: 0.1306 - val_accuracy: 0.0333\n",
      "Epoch 103/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 1.7007e-04 - accuracy: 0.0759 - val_loss: 0.1280 - val_accuracy: 0.0333\n",
      "Epoch 104/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.6647e-04 - accuracy: 0.0801 - val_loss: 0.1284 - val_accuracy: 0.0381\n",
      "Epoch 105/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 1.5637e-04 - accuracy: 0.0849 - val_loss: 0.1297 - val_accuracy: 0.0190\n",
      "Epoch 106/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 1.7207e-04 - accuracy: 0.0796 - val_loss: 0.1290 - val_accuracy: 0.0619\n",
      "Epoch 107/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 1.5759e-04 - accuracy: 0.0753 - val_loss: 0.1273 - val_accuracy: 0.0333\n",
      "Epoch 108/800\n",
      "59/59 [==============================] - 12s 210ms/step - loss: 1.4536e-04 - accuracy: 0.0865 - val_loss: 0.1273 - val_accuracy: 0.0190\n",
      "Epoch 109/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 1.6538e-04 - accuracy: 0.0817 - val_loss: 0.1274 - val_accuracy: 0.0524\n",
      "Epoch 110/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 1.3725e-04 - accuracy: 0.0838 - val_loss: 0.1264 - val_accuracy: 0.0381\n",
      "Epoch 111/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.5611e-04 - accuracy: 0.0759 - val_loss: 0.1340 - val_accuracy: 0.0571\n",
      "Epoch 112/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.3554e-04 - accuracy: 0.0838 - val_loss: 0.1299 - val_accuracy: 0.0381\n",
      "Epoch 113/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.3691e-04 - accuracy: 0.0790 - val_loss: 0.1296 - val_accuracy: 0.0381\n",
      "Epoch 114/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.4283e-04 - accuracy: 0.0822 - val_loss: 0.1302 - val_accuracy: 0.0238\n",
      "Epoch 115/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.2989e-04 - accuracy: 0.0812 - val_loss: 0.1245 - val_accuracy: 0.0190\n",
      "Epoch 116/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.3330e-04 - accuracy: 0.0828 - val_loss: 0.1269 - val_accuracy: 0.0190\n",
      "Epoch 117/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 1.2875e-04 - accuracy: 0.0822 - val_loss: 0.1305 - val_accuracy: 0.0238\n",
      "Epoch 118/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.3986e-04 - accuracy: 0.0796 - val_loss: 0.1310 - val_accuracy: 0.0619\n",
      "Epoch 119/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.6973e-04 - accuracy: 0.0939 - val_loss: 0.1273 - val_accuracy: 0.0190\n",
      "Epoch 120/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 1.3456e-04 - accuracy: 0.0891 - val_loss: 0.1280 - val_accuracy: 0.0143\n",
      "Epoch 121/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.2663e-04 - accuracy: 0.0902 - val_loss: 0.1290 - val_accuracy: 0.0238\n",
      "Epoch 122/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.2362e-04 - accuracy: 0.0822 - val_loss: 0.1281 - val_accuracy: 0.0238\n",
      "Epoch 123/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.3011e-04 - accuracy: 0.0912 - val_loss: 0.1270 - val_accuracy: 0.0190\n",
      "Epoch 124/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.3548e-04 - accuracy: 0.0891 - val_loss: 0.1289 - val_accuracy: 0.0381\n",
      "Epoch 125/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 1.2969e-04 - accuracy: 0.0838 - val_loss: 0.1280 - val_accuracy: 0.0190\n",
      "Epoch 126/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.2929e-04 - accuracy: 0.0833 - val_loss: 0.1267 - val_accuracy: 0.0333\n",
      "Epoch 127/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.2566e-04 - accuracy: 0.0764 - val_loss: 0.1280 - val_accuracy: 0.0238\n",
      "Epoch 128/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 1.1636e-04 - accuracy: 0.0785 - val_loss: 0.1261 - val_accuracy: 0.0238\n",
      "Epoch 129/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 1.1414e-04 - accuracy: 0.0902 - val_loss: 0.1273 - val_accuracy: 0.0190\n",
      "Epoch 130/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 1.1469e-04 - accuracy: 0.0934 - val_loss: 0.1261 - val_accuracy: 0.0190\n",
      "Epoch 131/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 1.1655e-04 - accuracy: 0.0902 - val_loss: 0.1276 - val_accuracy: 0.0286\n",
      "Epoch 132/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.2247e-04 - accuracy: 0.0907 - val_loss: 0.1251 - val_accuracy: 0.0286\n",
      "Epoch 133/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.2118e-04 - accuracy: 0.0822 - val_loss: 0.1256 - val_accuracy: 0.0190\n",
      "Epoch 134/800\n",
      "59/59 [==============================] - 14s 238ms/step - loss: 1.1969e-04 - accuracy: 0.0934 - val_loss: 0.1276 - val_accuracy: 0.0286\n",
      "Epoch 135/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 1.1531e-04 - accuracy: 0.0902 - val_loss: 0.1279 - val_accuracy: 0.0238\n",
      "Epoch 136/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 1.4583e-04 - accuracy: 0.0897 - val_loss: 0.1196 - val_accuracy: 0.0143\n",
      "Epoch 137/800\n",
      "59/59 [==============================] - 13s 225ms/step - loss: 1.3807e-04 - accuracy: 0.0902 - val_loss: 0.1435 - val_accuracy: 0.0238\n",
      "Epoch 138/800\n",
      "59/59 [==============================] - 13s 227ms/step - loss: 1.8987e-04 - accuracy: 0.0854 - val_loss: 0.1300 - val_accuracy: 0.0190\n",
      "Epoch 139/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 1.2055e-04 - accuracy: 0.0897 - val_loss: 0.1232 - val_accuracy: 0.0238\n",
      "Epoch 140/800\n",
      "59/59 [==============================] - 14s 245ms/step - loss: 1.1115e-04 - accuracy: 0.0981 - val_loss: 0.1295 - val_accuracy: 0.0190\n",
      "Epoch 141/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 1.1342e-04 - accuracy: 0.0897 - val_loss: 0.1286 - val_accuracy: 0.0333\n",
      "Epoch 142/800\n",
      "59/59 [==============================] - 12s 210ms/step - loss: 1.0935e-04 - accuracy: 0.0981 - val_loss: 0.1254 - val_accuracy: 0.0238\n",
      "Epoch 143/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.0975e-04 - accuracy: 0.0907 - val_loss: 0.1231 - val_accuracy: 0.0190\n",
      "Epoch 144/800\n",
      "59/59 [==============================] - 14s 236ms/step - loss: 1.1144e-04 - accuracy: 0.0902 - val_loss: 0.1247 - val_accuracy: 0.0238\n",
      "Epoch 145/800\n",
      "59/59 [==============================] - 16s 265ms/step - loss: 1.0721e-04 - accuracy: 0.0886 - val_loss: 0.1234 - val_accuracy: 0.0238\n",
      "Epoch 146/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 1.1345e-04 - accuracy: 0.0939 - val_loss: 0.1245 - val_accuracy: 0.0190\n",
      "Epoch 147/800\n",
      "59/59 [==============================] - 11s 191ms/step - loss: 1.1493e-04 - accuracy: 0.1003 - val_loss: 0.1225 - val_accuracy: 0.0143\n",
      "Epoch 148/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0588e-04 - accuracy: 0.0870 - val_loss: 0.1243 - val_accuracy: 0.0238\n",
      "Epoch 149/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 1.0408e-04 - accuracy: 0.0934 - val_loss: 0.1249 - val_accuracy: 0.0238\n",
      "Epoch 150/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0164e-04 - accuracy: 0.0907 - val_loss: 0.1275 - val_accuracy: 0.0286\n",
      "Epoch 151/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.0938e-04 - accuracy: 0.0870 - val_loss: 0.1236 - val_accuracy: 0.0143\n",
      "Epoch 152/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0926e-04 - accuracy: 0.0881 - val_loss: 0.1252 - val_accuracy: 0.0190\n",
      "Epoch 153/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.0544e-04 - accuracy: 0.0912 - val_loss: 0.1255 - val_accuracy: 0.0190\n",
      "Epoch 154/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0257e-04 - accuracy: 0.1098 - val_loss: 0.1246 - val_accuracy: 0.0238\n",
      "Epoch 155/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0698e-04 - accuracy: 0.0891 - val_loss: 0.1264 - val_accuracy: 0.0286\n",
      "Epoch 156/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.1034e-04 - accuracy: 0.0934 - val_loss: 0.1238 - val_accuracy: 0.0238\n",
      "Epoch 157/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0022e-04 - accuracy: 0.0987 - val_loss: 0.1233 - val_accuracy: 0.0238\n",
      "Epoch 158/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.0247e-04 - accuracy: 0.0971 - val_loss: 0.1234 - val_accuracy: 0.0190\n",
      "Epoch 159/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 9.8216e-05 - accuracy: 0.0928 - val_loss: 0.1212 - val_accuracy: 0.0143\n",
      "Epoch 160/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.0433e-04 - accuracy: 0.0859 - val_loss: 0.1225 - val_accuracy: 0.0095\n",
      "Epoch 161/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 9.6897e-05 - accuracy: 0.0944 - val_loss: 0.1226 - val_accuracy: 0.0238\n",
      "Epoch 162/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 9.5459e-05 - accuracy: 0.0966 - val_loss: 0.1231 - val_accuracy: 0.0238\n",
      "Epoch 163/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 1.0076e-04 - accuracy: 0.1008 - val_loss: 0.1206 - val_accuracy: 0.0381\n",
      "Epoch 164/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0251e-04 - accuracy: 0.1003 - val_loss: 0.1226 - val_accuracy: 0.0238\n",
      "Epoch 165/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 1.1641e-04 - accuracy: 0.1008 - val_loss: 0.1248 - val_accuracy: 0.0143\n",
      "Epoch 166/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.0087e-04 - accuracy: 0.0966 - val_loss: 0.1198 - val_accuracy: 0.0333\n",
      "Epoch 167/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 9.6860e-05 - accuracy: 0.1024 - val_loss: 0.1248 - val_accuracy: 0.0190\n",
      "Epoch 168/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 9.3886e-05 - accuracy: 0.1024 - val_loss: 0.1229 - val_accuracy: 0.0286\n",
      "Epoch 169/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 1.1155e-04 - accuracy: 0.0881 - val_loss: 0.1192 - val_accuracy: 0.0238\n",
      "Epoch 170/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0033e-04 - accuracy: 0.1066 - val_loss: 0.1221 - val_accuracy: 0.0238\n",
      "Epoch 171/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.3048e-04 - accuracy: 0.0950 - val_loss: 0.1268 - val_accuracy: 0.0333\n",
      "Epoch 172/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.1931e-04 - accuracy: 0.1040 - val_loss: 0.1198 - val_accuracy: 0.0238\n",
      "Epoch 173/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.3233e-04 - accuracy: 0.0875 - val_loss: 0.1250 - val_accuracy: 0.0238\n",
      "Epoch 174/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0657e-04 - accuracy: 0.0997 - val_loss: 0.1240 - val_accuracy: 0.0238\n",
      "Epoch 175/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 9.3091e-05 - accuracy: 0.1109 - val_loss: 0.1219 - val_accuracy: 0.0286\n",
      "Epoch 176/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 8.9986e-05 - accuracy: 0.1019 - val_loss: 0.1251 - val_accuracy: 0.0190\n",
      "Epoch 177/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 8.4656e-05 - accuracy: 0.0987 - val_loss: 0.1255 - val_accuracy: 0.0333\n",
      "Epoch 178/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 9.6161e-05 - accuracy: 0.0950 - val_loss: 0.1247 - val_accuracy: 0.0190\n",
      "Epoch 179/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 8.7978e-05 - accuracy: 0.0923 - val_loss: 0.1235 - val_accuracy: 0.0238\n",
      "Epoch 180/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 8.8824e-05 - accuracy: 0.0992 - val_loss: 0.1239 - val_accuracy: 0.0190\n",
      "Epoch 181/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 8.2422e-05 - accuracy: 0.0928 - val_loss: 0.1241 - val_accuracy: 0.0190\n",
      "Epoch 182/800\n",
      "59/59 [==============================] - 16s 277ms/step - loss: 8.1879e-05 - accuracy: 0.1003 - val_loss: 0.1226 - val_accuracy: 0.0476\n",
      "Epoch 183/800\n",
      "59/59 [==============================] - 15s 262ms/step - loss: 8.1154e-05 - accuracy: 0.0971 - val_loss: 0.1205 - val_accuracy: 0.0381\n",
      "Epoch 184/800\n",
      "59/59 [==============================] - 13s 228ms/step - loss: 8.3398e-05 - accuracy: 0.0976 - val_loss: 0.1234 - val_accuracy: 0.0429\n",
      "Epoch 185/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 1.0913e-04 - accuracy: 0.0833 - val_loss: 0.1233 - val_accuracy: 0.0333\n",
      "Epoch 186/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 9.3866e-05 - accuracy: 0.0912 - val_loss: 0.1216 - val_accuracy: 0.0190\n",
      "Epoch 187/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 8.4555e-05 - accuracy: 0.0992 - val_loss: 0.1238 - val_accuracy: 0.0286\n",
      "Epoch 188/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 8.7972e-05 - accuracy: 0.0987 - val_loss: 0.1233 - val_accuracy: 0.0429\n",
      "Epoch 189/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 7.8120e-05 - accuracy: 0.0950 - val_loss: 0.1253 - val_accuracy: 0.0238\n",
      "Epoch 190/800\n",
      "59/59 [==============================] - 13s 226ms/step - loss: 9.9421e-05 - accuracy: 0.0934 - val_loss: 0.1138 - val_accuracy: 0.0333\n",
      "Epoch 191/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 8.7200e-05 - accuracy: 0.1008 - val_loss: 0.1240 - val_accuracy: 0.0381\n",
      "Epoch 192/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 8.0099e-05 - accuracy: 0.1008 - val_loss: 0.1248 - val_accuracy: 0.0238\n",
      "Epoch 193/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.6706e-05 - accuracy: 0.0944 - val_loss: 0.1220 - val_accuracy: 0.0143\n",
      "Epoch 194/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 8.6120e-05 - accuracy: 0.0971 - val_loss: 0.1223 - val_accuracy: 0.0238\n",
      "Epoch 195/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.8618e-05 - accuracy: 0.0934 - val_loss: 0.1264 - val_accuracy: 0.0190\n",
      "Epoch 196/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 8.1669e-05 - accuracy: 0.0939 - val_loss: 0.1235 - val_accuracy: 0.0286\n",
      "Epoch 197/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.8306e-05 - accuracy: 0.1050 - val_loss: 0.1254 - val_accuracy: 0.0429\n",
      "Epoch 198/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 8.0099e-05 - accuracy: 0.0939 - val_loss: 0.1268 - val_accuracy: 0.0381\n",
      "Epoch 199/800\n",
      "59/59 [==============================] - 14s 231ms/step - loss: 7.8897e-05 - accuracy: 0.1003 - val_loss: 0.1223 - val_accuracy: 0.0476\n",
      "Epoch 200/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 1.2012e-04 - accuracy: 0.0918 - val_loss: 0.1253 - val_accuracy: 0.0476\n",
      "Epoch 201/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 9.3905e-05 - accuracy: 0.1024 - val_loss: 0.1275 - val_accuracy: 0.0238\n",
      "Epoch 202/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.6509e-05 - accuracy: 0.0971 - val_loss: 0.1245 - val_accuracy: 0.0286\n",
      "Epoch 203/800\n",
      "59/59 [==============================] - 12s 195ms/step - loss: 7.5963e-05 - accuracy: 0.1072 - val_loss: 0.1237 - val_accuracy: 0.0381\n",
      "Epoch 204/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 7.7184e-05 - accuracy: 0.1019 - val_loss: 0.1268 - val_accuracy: 0.0238\n",
      "Epoch 205/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.9789e-05 - accuracy: 0.0902 - val_loss: 0.1242 - val_accuracy: 0.0190\n",
      "Epoch 206/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.3133e-05 - accuracy: 0.1077 - val_loss: 0.1281 - val_accuracy: 0.0381\n",
      "Epoch 207/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 7.2169e-05 - accuracy: 0.0966 - val_loss: 0.1264 - val_accuracy: 0.0429\n",
      "Epoch 208/800\n",
      "59/59 [==============================] - 12s 212ms/step - loss: 7.0519e-05 - accuracy: 0.0981 - val_loss: 0.1255 - val_accuracy: 0.0476\n",
      "Epoch 209/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.8235e-05 - accuracy: 0.0944 - val_loss: 0.1219 - val_accuracy: 0.0381\n",
      "Epoch 210/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.9893e-05 - accuracy: 0.0987 - val_loss: 0.1278 - val_accuracy: 0.0143\n",
      "Epoch 211/800\n",
      "59/59 [==============================] - 12s 195ms/step - loss: 6.9845e-05 - accuracy: 0.0923 - val_loss: 0.1259 - val_accuracy: 0.0238\n",
      "Epoch 212/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.4989e-05 - accuracy: 0.0976 - val_loss: 0.1289 - val_accuracy: 0.0333\n",
      "Epoch 213/800\n",
      "59/59 [==============================] - 11s 195ms/step - loss: 7.5176e-05 - accuracy: 0.0997 - val_loss: 0.1251 - val_accuracy: 0.0381\n",
      "Epoch 214/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.1154e-05 - accuracy: 0.1013 - val_loss: 0.1263 - val_accuracy: 0.0381\n",
      "Epoch 215/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 7.4581e-05 - accuracy: 0.1034 - val_loss: 0.1265 - val_accuracy: 0.0286\n",
      "Epoch 216/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 6.9558e-05 - accuracy: 0.1077 - val_loss: 0.1280 - val_accuracy: 0.0286\n",
      "Epoch 217/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 6.8785e-05 - accuracy: 0.0944 - val_loss: 0.1252 - val_accuracy: 0.0333\n",
      "Epoch 218/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 6.9089e-05 - accuracy: 0.0971 - val_loss: 0.1259 - val_accuracy: 0.0143\n",
      "Epoch 219/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 6.9007e-05 - accuracy: 0.0971 - val_loss: 0.1282 - val_accuracy: 0.0286\n",
      "Epoch 220/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 6.9867e-05 - accuracy: 0.1066 - val_loss: 0.1283 - val_accuracy: 0.0476\n",
      "Epoch 221/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 6.7644e-05 - accuracy: 0.0955 - val_loss: 0.1253 - val_accuracy: 0.0190\n",
      "Epoch 222/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.0572e-05 - accuracy: 0.1130 - val_loss: 0.1256 - val_accuracy: 0.0190\n",
      "Epoch 223/800\n",
      "59/59 [==============================] - 12s 195ms/step - loss: 7.5148e-05 - accuracy: 0.1135 - val_loss: 0.1251 - val_accuracy: 0.0286\n",
      "Epoch 224/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 6.9107e-05 - accuracy: 0.1077 - val_loss: 0.1264 - val_accuracy: 0.0381\n",
      "Epoch 225/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 7.2554e-05 - accuracy: 0.0992 - val_loss: 0.1269 - val_accuracy: 0.0476\n",
      "Epoch 226/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 6.5629e-05 - accuracy: 0.1003 - val_loss: 0.1294 - val_accuracy: 0.0429\n",
      "Epoch 227/800\n",
      "59/59 [==============================] - 14s 245ms/step - loss: 6.8428e-05 - accuracy: 0.0923 - val_loss: 0.1291 - val_accuracy: 0.0333\n",
      "Epoch 228/800\n",
      "59/59 [==============================] - 13s 225ms/step - loss: 7.0819e-05 - accuracy: 0.1008 - val_loss: 0.1313 - val_accuracy: 0.0429\n",
      "Epoch 229/800\n",
      "59/59 [==============================] - 13s 229ms/step - loss: 6.6695e-05 - accuracy: 0.1013 - val_loss: 0.1259 - val_accuracy: 0.0429\n",
      "Epoch 230/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 6.8362e-05 - accuracy: 0.0992 - val_loss: 0.1268 - val_accuracy: 0.0238\n",
      "Epoch 231/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 6.5926e-05 - accuracy: 0.0976 - val_loss: 0.1286 - val_accuracy: 0.0381\n",
      "Epoch 232/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 8.0233e-05 - accuracy: 0.0997 - val_loss: 0.1213 - val_accuracy: 0.0381\n",
      "Epoch 233/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 4.7401e-04 - accuracy: 0.0806 - val_loss: 0.1347 - val_accuracy: 0.0381\n",
      "Epoch 234/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 2.5767e-04 - accuracy: 0.0769 - val_loss: 0.1206 - val_accuracy: 0.0667\n",
      "Epoch 235/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 1.9150e-04 - accuracy: 0.0849 - val_loss: 0.1314 - val_accuracy: 0.0524\n",
      "Epoch 236/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 1.5686e-04 - accuracy: 0.0833 - val_loss: 0.1288 - val_accuracy: 0.0714\n",
      "Epoch 237/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 1.3244e-04 - accuracy: 0.0955 - val_loss: 0.1279 - val_accuracy: 0.0238\n",
      "Epoch 238/800\n",
      "59/59 [==============================] - 11s 191ms/step - loss: 3.4198e-04 - accuracy: 0.0828 - val_loss: 0.1035 - val_accuracy: 0.0238\n",
      "Epoch 239/800\n",
      "59/59 [==============================] - 17s 291ms/step - loss: 2.4259e-04 - accuracy: 0.0711 - val_loss: 0.1276 - val_accuracy: 0.0667\n",
      "Epoch 240/800\n",
      "59/59 [==============================] - 16s 277ms/step - loss: 1.5105e-04 - accuracy: 0.0902 - val_loss: 0.1299 - val_accuracy: 0.0619\n",
      "Epoch 241/800\n",
      "59/59 [==============================] - 15s 260ms/step - loss: 1.2189e-04 - accuracy: 0.0844 - val_loss: 0.1286 - val_accuracy: 0.0524\n",
      "Epoch 242/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 1.1394e-04 - accuracy: 0.0897 - val_loss: 0.1279 - val_accuracy: 0.0238\n",
      "Epoch 243/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 1.1146e-04 - accuracy: 0.0950 - val_loss: 0.1276 - val_accuracy: 0.0524\n",
      "Epoch 244/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 1.0145e-04 - accuracy: 0.0897 - val_loss: 0.1299 - val_accuracy: 0.0429\n",
      "Epoch 245/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 1.0318e-04 - accuracy: 0.0960 - val_loss: 0.1293 - val_accuracy: 0.0524\n",
      "Epoch 246/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 1.0325e-04 - accuracy: 0.0881 - val_loss: 0.1332 - val_accuracy: 0.0333\n",
      "Epoch 247/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 9.7890e-05 - accuracy: 0.0881 - val_loss: 0.1346 - val_accuracy: 0.0190\n",
      "Epoch 248/800\n",
      "59/59 [==============================] - 18s 308ms/step - loss: 9.2848e-05 - accuracy: 0.0912 - val_loss: 0.1335 - val_accuracy: 0.0095\n",
      "Epoch 249/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 9.8351e-05 - accuracy: 0.1056 - val_loss: 0.1363 - val_accuracy: 0.0143\n",
      "Epoch 250/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 9.2169e-05 - accuracy: 0.0950 - val_loss: 0.1324 - val_accuracy: 0.0190\n",
      "Epoch 251/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 8.4942e-05 - accuracy: 0.1003 - val_loss: 0.1312 - val_accuracy: 0.0143\n",
      "Epoch 252/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 8.3789e-05 - accuracy: 0.1003 - val_loss: 0.1345 - val_accuracy: 0.0095\n",
      "Epoch 253/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.4752e-05 - accuracy: 0.1019 - val_loss: 0.1333 - val_accuracy: 0.0095\n",
      "Epoch 254/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 8.9309e-05 - accuracy: 0.0981 - val_loss: 0.1331 - val_accuracy: 0.0095\n",
      "Epoch 255/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.8575e-05 - accuracy: 0.0997 - val_loss: 0.1328 - val_accuracy: 0.0524\n",
      "Epoch 256/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.2595e-05 - accuracy: 0.1146 - val_loss: 0.1315 - val_accuracy: 0.0095\n",
      "Epoch 257/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.7314e-05 - accuracy: 0.0976 - val_loss: 0.1329 - val_accuracy: 0.0429\n",
      "Epoch 258/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 7.6755e-05 - accuracy: 0.1093 - val_loss: 0.1343 - val_accuracy: 0.0143\n",
      "Epoch 259/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.5248e-05 - accuracy: 0.1003 - val_loss: 0.1334 - val_accuracy: 0.0238\n",
      "Epoch 260/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 8.0357e-05 - accuracy: 0.0934 - val_loss: 0.1316 - val_accuracy: 0.0619\n",
      "Epoch 261/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.6465e-05 - accuracy: 0.1130 - val_loss: 0.1296 - val_accuracy: 0.0429\n",
      "Epoch 262/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.7675e-05 - accuracy: 0.1008 - val_loss: 0.1332 - val_accuracy: 0.0286\n",
      "Epoch 263/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.2036e-05 - accuracy: 0.0923 - val_loss: 0.1308 - val_accuracy: 0.0095\n",
      "Epoch 264/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 7.1323e-05 - accuracy: 0.0944 - val_loss: 0.1340 - val_accuracy: 0.0095\n",
      "Epoch 265/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.1889e-05 - accuracy: 0.0923 - val_loss: 0.1324 - val_accuracy: 0.0238\n",
      "Epoch 266/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 7.1893e-05 - accuracy: 0.0934 - val_loss: 0.1332 - val_accuracy: 0.0333\n",
      "Epoch 267/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 7.4007e-05 - accuracy: 0.1040 - val_loss: 0.1335 - val_accuracy: 0.0190\n",
      "Epoch 268/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 8.4765e-05 - accuracy: 0.0981 - val_loss: 0.1305 - val_accuracy: 0.0429\n",
      "Epoch 269/800\n",
      "59/59 [==============================] - 12s 195ms/step - loss: 7.4757e-05 - accuracy: 0.0992 - val_loss: 0.1323 - val_accuracy: 0.0286\n",
      "Epoch 270/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 7.3221e-05 - accuracy: 0.0976 - val_loss: 0.1311 - val_accuracy: 0.0286\n",
      "Epoch 271/800\n",
      "59/59 [==============================] - 12s 198ms/step - loss: 6.4711e-05 - accuracy: 0.1008 - val_loss: 0.1315 - val_accuracy: 0.0190\n",
      "Epoch 272/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 6.4482e-05 - accuracy: 0.1098 - val_loss: 0.1351 - val_accuracy: 0.0333\n",
      "Epoch 273/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 7.5770e-05 - accuracy: 0.1045 - val_loss: 0.1355 - val_accuracy: 0.0333\n",
      "Epoch 274/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 7.0517e-05 - accuracy: 0.0944 - val_loss: 0.1323 - val_accuracy: 0.0524\n",
      "Epoch 275/800\n",
      "59/59 [==============================] - 10s 174ms/step - loss: 6.7253e-05 - accuracy: 0.0997 - val_loss: 0.1318 - val_accuracy: 0.0333\n",
      "Epoch 276/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 6.6213e-05 - accuracy: 0.1029 - val_loss: 0.1313 - val_accuracy: 0.0238\n",
      "Epoch 277/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.7351e-05 - accuracy: 0.1056 - val_loss: 0.1319 - val_accuracy: 0.0571\n",
      "Epoch 278/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 7.8305e-05 - accuracy: 0.1114 - val_loss: 0.1346 - val_accuracy: 0.0333\n",
      "Epoch 279/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 7.1554e-05 - accuracy: 0.1034 - val_loss: 0.1331 - val_accuracy: 0.0381\n",
      "Epoch 280/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 6.2306e-05 - accuracy: 0.1008 - val_loss: 0.1324 - val_accuracy: 0.0619\n",
      "Epoch 281/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 6.6267e-05 - accuracy: 0.1050 - val_loss: 0.1333 - val_accuracy: 0.0286\n",
      "Epoch 282/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.5509e-05 - accuracy: 0.1236 - val_loss: 0.1329 - val_accuracy: 0.0429\n",
      "Epoch 283/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.4046e-05 - accuracy: 0.1050 - val_loss: 0.1322 - val_accuracy: 0.0333\n",
      "Epoch 284/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 6.9583e-05 - accuracy: 0.1162 - val_loss: 0.1303 - val_accuracy: 0.0190\n",
      "Epoch 285/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 6.8911e-05 - accuracy: 0.1072 - val_loss: 0.1301 - val_accuracy: 0.0095\n",
      "Epoch 286/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.0765e-05 - accuracy: 0.1040 - val_loss: 0.1322 - val_accuracy: 0.0619\n",
      "Epoch 287/800\n",
      "59/59 [==============================] - 10s 174ms/step - loss: 6.0183e-05 - accuracy: 0.1003 - val_loss: 0.1303 - val_accuracy: 0.0571\n",
      "Epoch 288/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 5.8723e-05 - accuracy: 0.1013 - val_loss: 0.1323 - val_accuracy: 0.0143\n",
      "Epoch 289/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 6.2744e-05 - accuracy: 0.1146 - val_loss: 0.1297 - val_accuracy: 0.0286\n",
      "Epoch 290/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.1153e-05 - accuracy: 0.1103 - val_loss: 0.1309 - val_accuracy: 0.0286\n",
      "Epoch 291/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 5.7538e-05 - accuracy: 0.1056 - val_loss: 0.1323 - val_accuracy: 0.0524\n",
      "Epoch 292/800\n",
      "59/59 [==============================] - 10s 174ms/step - loss: 5.9707e-05 - accuracy: 0.1072 - val_loss: 0.1327 - val_accuracy: 0.0238\n",
      "Epoch 293/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 5.8672e-05 - accuracy: 0.1008 - val_loss: 0.1320 - val_accuracy: 0.0429\n",
      "Epoch 294/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 6.9145e-05 - accuracy: 0.1061 - val_loss: 0.1303 - val_accuracy: 0.0286\n",
      "Epoch 295/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.6565e-05 - accuracy: 0.1077 - val_loss: 0.1320 - val_accuracy: 0.0286\n",
      "Epoch 296/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 5.5794e-05 - accuracy: 0.1061 - val_loss: 0.1311 - val_accuracy: 0.0190\n",
      "Epoch 297/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 5.6913e-05 - accuracy: 0.1029 - val_loss: 0.1308 - val_accuracy: 0.0286\n",
      "Epoch 298/800\n",
      "59/59 [==============================] - 14s 236ms/step - loss: 5.6088e-05 - accuracy: 0.1077 - val_loss: 0.1311 - val_accuracy: 0.0238\n",
      "Epoch 299/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 6.0245e-05 - accuracy: 0.1167 - val_loss: 0.1289 - val_accuracy: 0.0429\n",
      "Epoch 300/800\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 6.8018e-05 - accuracy: 0.1125 - val_loss: 0.1275 - val_accuracy: 0.0286\n",
      "Epoch 301/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 6.2065e-05 - accuracy: 0.1077 - val_loss: 0.1321 - val_accuracy: 0.0476\n",
      "Epoch 302/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 5.7741e-05 - accuracy: 0.1056 - val_loss: 0.1306 - val_accuracy: 0.0429\n",
      "Epoch 303/800\n",
      "59/59 [==============================] - 14s 244ms/step - loss: 5.2953e-05 - accuracy: 0.1008 - val_loss: 0.1344 - val_accuracy: 0.0286\n",
      "Epoch 304/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 5.5024e-05 - accuracy: 0.1162 - val_loss: 0.1323 - val_accuracy: 0.0286\n",
      "Epoch 305/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 5.2920e-05 - accuracy: 0.1056 - val_loss: 0.1314 - val_accuracy: 0.0286\n",
      "Epoch 306/800\n",
      "59/59 [==============================] - 15s 260ms/step - loss: 5.4860e-05 - accuracy: 0.1172 - val_loss: 0.1313 - val_accuracy: 0.0238\n",
      "Epoch 307/800\n",
      "59/59 [==============================] - 15s 247ms/step - loss: 8.5127e-05 - accuracy: 0.1088 - val_loss: 0.1339 - val_accuracy: 0.0143\n",
      "Epoch 308/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 4.2601e-04 - accuracy: 0.0769 - val_loss: 0.1185 - val_accuracy: 0.0238\n",
      "Epoch 309/800\n",
      "59/59 [==============================] - 12s 196ms/step - loss: 5.2132e-04 - accuracy: 0.0732 - val_loss: 0.1377 - val_accuracy: 0.0333\n",
      "Epoch 310/800\n",
      "59/59 [==============================] - 12s 199ms/step - loss: 2.4909e-04 - accuracy: 0.1050 - val_loss: 0.1462 - val_accuracy: 0.0571\n",
      "Epoch 311/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 1.6711e-04 - accuracy: 0.1130 - val_loss: 0.1377 - val_accuracy: 0.0571\n",
      "Epoch 312/800\n",
      "59/59 [==============================] - 15s 255ms/step - loss: 1.2153e-04 - accuracy: 0.1141 - val_loss: 0.1383 - val_accuracy: 0.0667\n",
      "Epoch 313/800\n",
      "59/59 [==============================] - 18s 297ms/step - loss: 1.2637e-04 - accuracy: 0.1119 - val_loss: 0.1313 - val_accuracy: 0.0190\n",
      "Epoch 314/800\n",
      "59/59 [==============================] - 16s 270ms/step - loss: 1.0768e-04 - accuracy: 0.1093 - val_loss: 0.1368 - val_accuracy: 0.0238\n",
      "Epoch 315/800\n",
      "59/59 [==============================] - 15s 260ms/step - loss: 8.3525e-05 - accuracy: 0.1119 - val_loss: 0.1331 - val_accuracy: 0.0524\n",
      "Epoch 316/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 8.0504e-05 - accuracy: 0.1024 - val_loss: 0.1362 - val_accuracy: 0.0286\n",
      "Epoch 317/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 8.3046e-05 - accuracy: 0.1082 - val_loss: 0.1325 - val_accuracy: 0.0571\n",
      "Epoch 318/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 7.8062e-05 - accuracy: 0.1130 - val_loss: 0.1362 - val_accuracy: 0.0571\n",
      "Epoch 319/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 8.7032e-05 - accuracy: 0.1125 - val_loss: 0.1326 - val_accuracy: 0.0476\n",
      "Epoch 320/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 7.0250e-05 - accuracy: 0.1088 - val_loss: 0.1321 - val_accuracy: 0.0524\n",
      "Epoch 321/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 7.6648e-05 - accuracy: 0.1088 - val_loss: 0.1357 - val_accuracy: 0.0476\n",
      "Epoch 322/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 6.8055e-05 - accuracy: 0.1156 - val_loss: 0.1360 - val_accuracy: 0.0571\n",
      "Epoch 323/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 6.4840e-05 - accuracy: 0.1082 - val_loss: 0.1336 - val_accuracy: 0.0286\n",
      "Epoch 324/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 6.2983e-05 - accuracy: 0.1178 - val_loss: 0.1346 - val_accuracy: 0.0524\n",
      "Epoch 325/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 6.3876e-05 - accuracy: 0.1082 - val_loss: 0.1349 - val_accuracy: 0.0381\n",
      "Epoch 326/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.4460e-05 - accuracy: 0.1178 - val_loss: 0.1338 - val_accuracy: 0.0619\n",
      "Epoch 327/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 6.6392e-05 - accuracy: 0.1103 - val_loss: 0.1344 - val_accuracy: 0.0238\n",
      "Epoch 328/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 6.0120e-05 - accuracy: 0.1162 - val_loss: 0.1338 - val_accuracy: 0.0476\n",
      "Epoch 329/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 6.0848e-05 - accuracy: 0.1215 - val_loss: 0.1344 - val_accuracy: 0.0524\n",
      "Epoch 330/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 6.2102e-05 - accuracy: 0.1156 - val_loss: 0.1345 - val_accuracy: 0.0524\n",
      "Epoch 331/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 5.9061e-05 - accuracy: 0.1151 - val_loss: 0.1343 - val_accuracy: 0.0476\n",
      "Epoch 332/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 5.7408e-05 - accuracy: 0.1146 - val_loss: 0.1345 - val_accuracy: 0.0571\n",
      "Epoch 333/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 5.4601e-05 - accuracy: 0.1082 - val_loss: 0.1343 - val_accuracy: 0.0238\n",
      "Epoch 334/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 5.4971e-05 - accuracy: 0.1188 - val_loss: 0.1359 - val_accuracy: 0.0571\n",
      "Epoch 335/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.3813e-05 - accuracy: 0.1247 - val_loss: 0.1372 - val_accuracy: 0.0476\n",
      "Epoch 336/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.3441e-05 - accuracy: 0.1225 - val_loss: 0.1358 - val_accuracy: 0.0286\n",
      "Epoch 337/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 5.6848e-05 - accuracy: 0.1268 - val_loss: 0.1356 - val_accuracy: 0.0714\n",
      "Epoch 338/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.2079e-05 - accuracy: 0.1305 - val_loss: 0.1351 - val_accuracy: 0.0476\n",
      "Epoch 339/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 5.0149e-05 - accuracy: 0.1130 - val_loss: 0.1365 - val_accuracy: 0.0381\n",
      "Epoch 340/800\n",
      "59/59 [==============================] - 11s 182ms/step - loss: 5.3750e-05 - accuracy: 0.1225 - val_loss: 0.1362 - val_accuracy: 0.0476\n",
      "Epoch 341/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 6.2020e-05 - accuracy: 0.1220 - val_loss: 0.1346 - val_accuracy: 0.0524\n",
      "Epoch 342/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.0924e-05 - accuracy: 0.1204 - val_loss: 0.1353 - val_accuracy: 0.0381\n",
      "Epoch 343/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 5.1307e-05 - accuracy: 0.1326 - val_loss: 0.1369 - val_accuracy: 0.0381\n",
      "Epoch 344/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 5.1431e-05 - accuracy: 0.1231 - val_loss: 0.1364 - val_accuracy: 0.0524\n",
      "Epoch 345/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 4.7773e-05 - accuracy: 0.1289 - val_loss: 0.1388 - val_accuracy: 0.0762\n",
      "Epoch 346/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.7466e-05 - accuracy: 0.1225 - val_loss: 0.1381 - val_accuracy: 0.0429\n",
      "Epoch 347/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 5.0002e-05 - accuracy: 0.1188 - val_loss: 0.1388 - val_accuracy: 0.0429\n",
      "Epoch 348/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 4.8126e-05 - accuracy: 0.1305 - val_loss: 0.1355 - val_accuracy: 0.0524\n",
      "Epoch 349/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.7077e-05 - accuracy: 0.1210 - val_loss: 0.1384 - val_accuracy: 0.0381\n",
      "Epoch 350/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 5.0901e-05 - accuracy: 0.1321 - val_loss: 0.1373 - val_accuracy: 0.0429\n",
      "Epoch 351/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 4.7955e-05 - accuracy: 0.1263 - val_loss: 0.1388 - val_accuracy: 0.0619\n",
      "Epoch 352/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.6212e-05 - accuracy: 0.1231 - val_loss: 0.1378 - val_accuracy: 0.0381\n",
      "Epoch 353/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.3338e-05 - accuracy: 0.1289 - val_loss: 0.1380 - val_accuracy: 0.0429\n",
      "Epoch 354/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 5.0007e-05 - accuracy: 0.1199 - val_loss: 0.1375 - val_accuracy: 0.0286\n",
      "Epoch 355/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.2117e-05 - accuracy: 0.1347 - val_loss: 0.1388 - val_accuracy: 0.0524\n",
      "Epoch 356/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 4.7404e-05 - accuracy: 0.1236 - val_loss: 0.1379 - val_accuracy: 0.0476\n",
      "Epoch 357/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 4.9593e-05 - accuracy: 0.1300 - val_loss: 0.1402 - val_accuracy: 0.0286\n",
      "Epoch 358/800\n",
      "59/59 [==============================] - 15s 254ms/step - loss: 4.6522e-05 - accuracy: 0.1204 - val_loss: 0.1384 - val_accuracy: 0.0524\n",
      "Epoch 359/800\n",
      "59/59 [==============================] - 14s 237ms/step - loss: 4.5524e-05 - accuracy: 0.1236 - val_loss: 0.1378 - val_accuracy: 0.0381\n",
      "Epoch 360/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 5.2556e-05 - accuracy: 0.1310 - val_loss: 0.1399 - val_accuracy: 0.0238\n",
      "Epoch 361/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 9.3995e-05 - accuracy: 0.1236 - val_loss: 0.1377 - val_accuracy: 0.0333\n",
      "Epoch 362/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 5.1421e-05 - accuracy: 0.1220 - val_loss: 0.1393 - val_accuracy: 0.0429\n",
      "Epoch 363/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 4.3757e-05 - accuracy: 0.1358 - val_loss: 0.1377 - val_accuracy: 0.0429\n",
      "Epoch 364/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 4.7847e-05 - accuracy: 0.1379 - val_loss: 0.1399 - val_accuracy: 0.0524\n",
      "Epoch 365/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 4.3023e-05 - accuracy: 0.1284 - val_loss: 0.1392 - val_accuracy: 0.0381\n",
      "Epoch 366/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 4.2550e-05 - accuracy: 0.1151 - val_loss: 0.1401 - val_accuracy: 0.0429\n",
      "Epoch 367/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 4.6871e-05 - accuracy: 0.1443 - val_loss: 0.1398 - val_accuracy: 0.0524\n",
      "Epoch 368/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 4.5667e-05 - accuracy: 0.1448 - val_loss: 0.1372 - val_accuracy: 0.0524\n",
      "Epoch 369/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 4.4234e-05 - accuracy: 0.1353 - val_loss: 0.1378 - val_accuracy: 0.0524\n",
      "Epoch 370/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 4.8497e-05 - accuracy: 0.1321 - val_loss: 0.1392 - val_accuracy: 0.0238\n",
      "Epoch 371/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 4.5166e-05 - accuracy: 0.1273 - val_loss: 0.1392 - val_accuracy: 0.0333\n",
      "Epoch 372/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 4.3103e-05 - accuracy: 0.1263 - val_loss: 0.1371 - val_accuracy: 0.0333\n",
      "Epoch 373/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 4.0939e-05 - accuracy: 0.1353 - val_loss: 0.1367 - val_accuracy: 0.0476\n",
      "Epoch 374/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 4.2009e-05 - accuracy: 0.1263 - val_loss: 0.1402 - val_accuracy: 0.0381\n",
      "Epoch 375/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 4.3409e-05 - accuracy: 0.1395 - val_loss: 0.1398 - val_accuracy: 0.0476\n",
      "Epoch 376/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 4.3242e-05 - accuracy: 0.1252 - val_loss: 0.1373 - val_accuracy: 0.0429\n",
      "Epoch 377/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 3.9986e-05 - accuracy: 0.1337 - val_loss: 0.1397 - val_accuracy: 0.0571\n",
      "Epoch 378/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 3.8464e-05 - accuracy: 0.1273 - val_loss: 0.1385 - val_accuracy: 0.0762\n",
      "Epoch 379/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 4.3289e-05 - accuracy: 0.1294 - val_loss: 0.1385 - val_accuracy: 0.0286\n",
      "Epoch 380/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 4.8600e-05 - accuracy: 0.1279 - val_loss: 0.1374 - val_accuracy: 0.0238\n",
      "Epoch 381/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 5.6506e-05 - accuracy: 0.1321 - val_loss: 0.1388 - val_accuracy: 0.0524\n",
      "Epoch 382/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 4.9848e-05 - accuracy: 0.1326 - val_loss: 0.1396 - val_accuracy: 0.0381\n",
      "Epoch 383/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 4.4031e-05 - accuracy: 0.1347 - val_loss: 0.1374 - val_accuracy: 0.0333\n",
      "Epoch 384/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 4.3244e-05 - accuracy: 0.1363 - val_loss: 0.1386 - val_accuracy: 0.0810\n",
      "Epoch 385/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 4.0380e-05 - accuracy: 0.1284 - val_loss: 0.1378 - val_accuracy: 0.0905\n",
      "Epoch 386/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 4.1775e-05 - accuracy: 0.1310 - val_loss: 0.1379 - val_accuracy: 0.0714\n",
      "Epoch 387/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 4.0253e-05 - accuracy: 0.1310 - val_loss: 0.1380 - val_accuracy: 0.0619\n",
      "Epoch 388/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 3.9560e-05 - accuracy: 0.1294 - val_loss: 0.1407 - val_accuracy: 0.0476\n",
      "Epoch 389/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 3.9449e-05 - accuracy: 0.1332 - val_loss: 0.1396 - val_accuracy: 0.0333\n",
      "Epoch 390/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 3.9537e-05 - accuracy: 0.1411 - val_loss: 0.1381 - val_accuracy: 0.0476\n",
      "Epoch 391/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 4.3856e-05 - accuracy: 0.1374 - val_loss: 0.1374 - val_accuracy: 0.0429\n",
      "Epoch 392/800\n",
      "59/59 [==============================] - 13s 218ms/step - loss: 4.0334e-05 - accuracy: 0.1342 - val_loss: 0.1387 - val_accuracy: 0.0524\n",
      "Epoch 393/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 5.5280e-05 - accuracy: 0.1422 - val_loss: 0.1376 - val_accuracy: 0.0429\n",
      "Epoch 394/800\n",
      "59/59 [==============================] - 13s 216ms/step - loss: 5.4059e-05 - accuracy: 0.1231 - val_loss: 0.1405 - val_accuracy: 0.0333\n",
      "Epoch 395/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 4.1277e-05 - accuracy: 0.1385 - val_loss: 0.1363 - val_accuracy: 0.0667\n",
      "Epoch 396/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 4.1768e-05 - accuracy: 0.1443 - val_loss: 0.1376 - val_accuracy: 0.0905\n",
      "Epoch 397/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 3.9988e-05 - accuracy: 0.1363 - val_loss: 0.1370 - val_accuracy: 0.0810\n",
      "Epoch 398/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.9041e-05 - accuracy: 0.1432 - val_loss: 0.1361 - val_accuracy: 0.0476\n",
      "Epoch 399/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.1143e-05 - accuracy: 0.1385 - val_loss: 0.1372 - val_accuracy: 0.0857\n",
      "Epoch 400/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.7439e-05 - accuracy: 0.1363 - val_loss: 0.1377 - val_accuracy: 0.0429\n",
      "Epoch 401/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.6010e-05 - accuracy: 0.1284 - val_loss: 0.1379 - val_accuracy: 0.0762\n",
      "Epoch 402/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 4.0562e-05 - accuracy: 0.1406 - val_loss: 0.1386 - val_accuracy: 0.0667\n",
      "Epoch 403/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.7741e-05 - accuracy: 0.1369 - val_loss: 0.1390 - val_accuracy: 0.0667\n",
      "Epoch 404/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 3.6779e-05 - accuracy: 0.1459 - val_loss: 0.1380 - val_accuracy: 0.0333\n",
      "Epoch 405/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.4836e-05 - accuracy: 0.1448 - val_loss: 0.1377 - val_accuracy: 0.0524\n",
      "Epoch 406/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 3.6745e-05 - accuracy: 0.1454 - val_loss: 0.1400 - val_accuracy: 0.0429\n",
      "Epoch 407/800\n",
      "59/59 [==============================] - 14s 236ms/step - loss: 4.0732e-05 - accuracy: 0.1353 - val_loss: 0.1392 - val_accuracy: 0.0476\n",
      "Epoch 408/800\n",
      "59/59 [==============================] - 13s 226ms/step - loss: 3.8565e-05 - accuracy: 0.1374 - val_loss: 0.1395 - val_accuracy: 0.0762\n",
      "Epoch 409/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 3.8480e-05 - accuracy: 0.1310 - val_loss: 0.1382 - val_accuracy: 0.0619\n",
      "Epoch 410/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 3.7277e-05 - accuracy: 0.1459 - val_loss: 0.1376 - val_accuracy: 0.0524\n",
      "Epoch 411/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 4.3972e-05 - accuracy: 0.1310 - val_loss: 0.1397 - val_accuracy: 0.0476\n",
      "Epoch 412/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 3.9979e-05 - accuracy: 0.1379 - val_loss: 0.1366 - val_accuracy: 0.0762\n",
      "Epoch 413/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.7663e-05 - accuracy: 0.1422 - val_loss: 0.1360 - val_accuracy: 0.0524\n",
      "Epoch 414/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.6647e-05 - accuracy: 0.1443 - val_loss: 0.1378 - val_accuracy: 0.0857\n",
      "Epoch 415/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.8357e-05 - accuracy: 0.1491 - val_loss: 0.1361 - val_accuracy: 0.0476\n",
      "Epoch 416/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 3.4963e-05 - accuracy: 0.1496 - val_loss: 0.1364 - val_accuracy: 0.0429\n",
      "Epoch 417/800\n",
      "59/59 [==============================] - 13s 228ms/step - loss: 3.6179e-05 - accuracy: 0.1385 - val_loss: 0.1383 - val_accuracy: 0.0476\n",
      "Epoch 418/800\n",
      "59/59 [==============================] - 20s 339ms/step - loss: 3.6978e-05 - accuracy: 0.1459 - val_loss: 0.1376 - val_accuracy: 0.0286\n",
      "Epoch 419/800\n",
      "59/59 [==============================] - 14s 240ms/step - loss: 3.7649e-05 - accuracy: 0.1485 - val_loss: 0.1384 - val_accuracy: 0.0619\n",
      "Epoch 420/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.9007e-05 - accuracy: 0.1395 - val_loss: 0.1365 - val_accuracy: 0.0810\n",
      "Epoch 421/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 4.5126e-05 - accuracy: 0.1347 - val_loss: 0.1400 - val_accuracy: 0.0524\n",
      "Epoch 422/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 4.3558e-05 - accuracy: 0.1432 - val_loss: 0.1367 - val_accuracy: 0.0619\n",
      "Epoch 423/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 4.4668e-05 - accuracy: 0.1395 - val_loss: 0.1340 - val_accuracy: 0.0905\n",
      "Epoch 424/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.8239e-05 - accuracy: 0.1300 - val_loss: 0.1360 - val_accuracy: 0.0571\n",
      "Epoch 425/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 4.0219e-05 - accuracy: 0.1300 - val_loss: 0.1352 - val_accuracy: 0.0524\n",
      "Epoch 426/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.5348e-05 - accuracy: 0.1310 - val_loss: 0.1345 - val_accuracy: 0.0381\n",
      "Epoch 427/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.5315e-05 - accuracy: 0.1300 - val_loss: 0.1360 - val_accuracy: 0.0857\n",
      "Epoch 428/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 4.0186e-05 - accuracy: 0.1454 - val_loss: 0.1390 - val_accuracy: 0.0571\n",
      "Epoch 429/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 4.3009e-05 - accuracy: 0.1464 - val_loss: 0.1363 - val_accuracy: 0.0333\n",
      "Epoch 430/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.9165e-05 - accuracy: 0.1390 - val_loss: 0.1346 - val_accuracy: 0.0810\n",
      "Epoch 431/800\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 3.8260e-05 - accuracy: 0.1406 - val_loss: 0.1344 - val_accuracy: 0.0762\n",
      "Epoch 432/800\n",
      "59/59 [==============================] - 11s 182ms/step - loss: 3.4076e-05 - accuracy: 0.1416 - val_loss: 0.1371 - val_accuracy: 0.0524\n",
      "Epoch 433/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 3.5975e-05 - accuracy: 0.1469 - val_loss: 0.1381 - val_accuracy: 0.0524\n",
      "Epoch 434/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.3272e-05 - accuracy: 0.1390 - val_loss: 0.1386 - val_accuracy: 0.0524\n",
      "Epoch 435/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.4984e-05 - accuracy: 0.1454 - val_loss: 0.1370 - val_accuracy: 0.0714\n",
      "Epoch 436/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.5840e-05 - accuracy: 0.1395 - val_loss: 0.1382 - val_accuracy: 0.0524\n",
      "Epoch 437/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.3689e-05 - accuracy: 0.1544 - val_loss: 0.1349 - val_accuracy: 0.0381\n",
      "Epoch 438/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.2311e-05 - accuracy: 0.1464 - val_loss: 0.1356 - val_accuracy: 0.0524\n",
      "Epoch 439/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.5856e-05 - accuracy: 0.1528 - val_loss: 0.1363 - val_accuracy: 0.0571\n",
      "Epoch 440/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.5310e-05 - accuracy: 0.1432 - val_loss: 0.1354 - val_accuracy: 0.0810\n",
      "Epoch 441/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.4054e-05 - accuracy: 0.1385 - val_loss: 0.1363 - val_accuracy: 0.0524\n",
      "Epoch 442/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.4153e-05 - accuracy: 0.1454 - val_loss: 0.1352 - val_accuracy: 0.0381\n",
      "Epoch 443/800\n",
      "59/59 [==============================] - 11s 185ms/step - loss: 3.2732e-05 - accuracy: 0.1459 - val_loss: 0.1353 - val_accuracy: 0.0476\n",
      "Epoch 444/800\n",
      "59/59 [==============================] - 11s 183ms/step - loss: 3.6974e-05 - accuracy: 0.1363 - val_loss: 0.1358 - val_accuracy: 0.0571\n",
      "Epoch 445/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 6.6131e-05 - accuracy: 0.1395 - val_loss: 0.1370 - val_accuracy: 0.0714\n",
      "Epoch 446/800\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 4.2879e-05 - accuracy: 0.1369 - val_loss: 0.1359 - val_accuracy: 0.0762\n",
      "Epoch 447/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.5225e-05 - accuracy: 0.1305 - val_loss: 0.1372 - val_accuracy: 0.0571\n",
      "Epoch 448/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 3.7698e-05 - accuracy: 0.1379 - val_loss: 0.1363 - val_accuracy: 0.0810\n",
      "Epoch 449/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.1806e-05 - accuracy: 0.1501 - val_loss: 0.1352 - val_accuracy: 0.0476\n",
      "Epoch 450/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.1705e-05 - accuracy: 0.1385 - val_loss: 0.1340 - val_accuracy: 0.0762\n",
      "Epoch 451/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.2354e-05 - accuracy: 0.1459 - val_loss: 0.1373 - val_accuracy: 0.0857\n",
      "Epoch 452/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.3231e-05 - accuracy: 0.1443 - val_loss: 0.1354 - val_accuracy: 0.0381\n",
      "Epoch 453/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.4120e-05 - accuracy: 0.1395 - val_loss: 0.1355 - val_accuracy: 0.0381\n",
      "Epoch 454/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.0681e-05 - accuracy: 0.1586 - val_loss: 0.1353 - val_accuracy: 0.0571\n",
      "Epoch 455/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 3.2271e-05 - accuracy: 0.1491 - val_loss: 0.1352 - val_accuracy: 0.0857\n",
      "Epoch 456/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.5296e-05 - accuracy: 0.1565 - val_loss: 0.1349 - val_accuracy: 0.0810\n",
      "Epoch 457/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.2425e-05 - accuracy: 0.1395 - val_loss: 0.1357 - val_accuracy: 0.0619\n",
      "Epoch 458/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.0964e-05 - accuracy: 0.1517 - val_loss: 0.1368 - val_accuracy: 0.0524\n",
      "Epoch 459/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.5232e-05 - accuracy: 0.1485 - val_loss: 0.1346 - val_accuracy: 0.0857\n",
      "Epoch 460/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.2074e-05 - accuracy: 0.1438 - val_loss: 0.1349 - val_accuracy: 0.0571\n",
      "Epoch 461/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.0156e-05 - accuracy: 0.1432 - val_loss: 0.1348 - val_accuracy: 0.0810\n",
      "Epoch 462/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.5340e-05 - accuracy: 0.1395 - val_loss: 0.1339 - val_accuracy: 0.0667\n",
      "Epoch 463/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.5933e-05 - accuracy: 0.1353 - val_loss: 0.1333 - val_accuracy: 0.0381\n",
      "Epoch 464/800\n",
      "59/59 [==============================] - 11s 182ms/step - loss: 3.2416e-05 - accuracy: 0.1438 - val_loss: 0.1339 - val_accuracy: 0.0667\n",
      "Epoch 465/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 3.1600e-05 - accuracy: 0.1581 - val_loss: 0.1339 - val_accuracy: 0.0524\n",
      "Epoch 466/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.2285e-05 - accuracy: 0.1469 - val_loss: 0.1317 - val_accuracy: 0.0762\n",
      "Epoch 467/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.7210e-05 - accuracy: 0.1538 - val_loss: 0.1319 - val_accuracy: 0.0571\n",
      "Epoch 468/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.8028e-05 - accuracy: 0.1480 - val_loss: 0.1319 - val_accuracy: 0.0524\n",
      "Epoch 469/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 3.7062e-05 - accuracy: 0.1438 - val_loss: 0.1348 - val_accuracy: 0.0762\n",
      "Epoch 470/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 3.4550e-05 - accuracy: 0.1523 - val_loss: 0.1344 - val_accuracy: 0.0667\n",
      "Epoch 471/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.1958e-05 - accuracy: 0.1538 - val_loss: 0.1341 - val_accuracy: 0.0714\n",
      "Epoch 472/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.1402e-05 - accuracy: 0.1538 - val_loss: 0.1346 - val_accuracy: 0.0857\n",
      "Epoch 473/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.1588e-05 - accuracy: 0.1459 - val_loss: 0.1331 - val_accuracy: 0.0810\n",
      "Epoch 474/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 5.7008e-05 - accuracy: 0.1252 - val_loss: 0.1358 - val_accuracy: 0.0667\n",
      "Epoch 475/800\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 3.2812e-05 - accuracy: 0.1475 - val_loss: 0.1346 - val_accuracy: 0.0810\n",
      "Epoch 476/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.0024e-05 - accuracy: 0.1560 - val_loss: 0.1345 - val_accuracy: 0.0571\n",
      "Epoch 477/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 2.9464e-05 - accuracy: 0.1507 - val_loss: 0.1337 - val_accuracy: 0.0857\n",
      "Epoch 478/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 2.8956e-05 - accuracy: 0.1639 - val_loss: 0.1339 - val_accuracy: 0.0667\n",
      "Epoch 479/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.1794e-05 - accuracy: 0.1475 - val_loss: 0.1337 - val_accuracy: 0.0857\n",
      "Epoch 480/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 2.9361e-05 - accuracy: 0.1459 - val_loss: 0.1328 - val_accuracy: 0.0571\n",
      "Epoch 481/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.0588e-05 - accuracy: 0.1613 - val_loss: 0.1324 - val_accuracy: 0.0905\n",
      "Epoch 482/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 3.0306e-05 - accuracy: 0.1480 - val_loss: 0.1338 - val_accuracy: 0.0524\n",
      "Epoch 483/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.0243e-05 - accuracy: 0.1491 - val_loss: 0.1331 - val_accuracy: 0.0810\n",
      "Epoch 484/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.2714e-05 - accuracy: 0.1512 - val_loss: 0.1324 - val_accuracy: 0.0762\n",
      "Epoch 485/800\n",
      "59/59 [==============================] - 10s 178ms/step - loss: 3.3600e-05 - accuracy: 0.1443 - val_loss: 0.1350 - val_accuracy: 0.0810\n",
      "Epoch 486/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 2.9591e-05 - accuracy: 0.1560 - val_loss: 0.1337 - val_accuracy: 0.0810\n",
      "Epoch 487/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 2.9714e-05 - accuracy: 0.1427 - val_loss: 0.1313 - val_accuracy: 0.0810\n",
      "Epoch 488/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 2.9105e-05 - accuracy: 0.1538 - val_loss: 0.1317 - val_accuracy: 0.0905\n",
      "Epoch 489/800\n",
      "59/59 [==============================] - 11s 183ms/step - loss: 3.0899e-05 - accuracy: 0.1528 - val_loss: 0.1339 - val_accuracy: 0.0714\n",
      "Epoch 490/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.1910e-05 - accuracy: 0.1538 - val_loss: 0.1324 - val_accuracy: 0.0524\n",
      "Epoch 491/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 3.1563e-05 - accuracy: 0.1475 - val_loss: 0.1344 - val_accuracy: 0.0857\n",
      "Epoch 492/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 5.1543e-05 - accuracy: 0.1443 - val_loss: 0.1323 - val_accuracy: 0.0571\n",
      "Epoch 493/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 4.1606e-05 - accuracy: 0.1560 - val_loss: 0.1294 - val_accuracy: 0.0429\n",
      "Epoch 494/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 2.9947e-05 - accuracy: 0.1422 - val_loss: 0.1320 - val_accuracy: 0.0905\n",
      "Epoch 495/800\n",
      "59/59 [==============================] - 11s 182ms/step - loss: 2.9416e-05 - accuracy: 0.1549 - val_loss: 0.1316 - val_accuracy: 0.0857\n",
      "Epoch 496/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.1576e-05 - accuracy: 0.1501 - val_loss: 0.1334 - val_accuracy: 0.0619\n",
      "Epoch 497/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 4.2825e-05 - accuracy: 0.1448 - val_loss: 0.1296 - val_accuracy: 0.0810\n",
      "Epoch 498/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.0355e-05 - accuracy: 0.1523 - val_loss: 0.1340 - val_accuracy: 0.0667\n",
      "Epoch 499/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 2.8270e-05 - accuracy: 0.1523 - val_loss: 0.1322 - val_accuracy: 0.0857\n",
      "Epoch 500/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 3.0333e-05 - accuracy: 0.1501 - val_loss: 0.1316 - val_accuracy: 0.0857\n",
      "Epoch 501/800\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 3.1212e-05 - accuracy: 0.1597 - val_loss: 0.1295 - val_accuracy: 0.0714\n",
      "Epoch 502/800\n",
      "59/59 [==============================] - 11s 178ms/step - loss: 3.0014e-05 - accuracy: 0.1507 - val_loss: 0.1323 - val_accuracy: 0.0381\n",
      "Epoch 503/800\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 2.7488e-05 - accuracy: 0.1523 - val_loss: 0.1317 - val_accuracy: 0.0857\n",
      "Epoch 504/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 2.7969e-05 - accuracy: 0.1613 - val_loss: 0.1324 - val_accuracy: 0.0810\n",
      "Epoch 505/800\n",
      "59/59 [==============================] - 13s 227ms/step - loss: 2.8978e-05 - accuracy: 0.1549 - val_loss: 0.1329 - val_accuracy: 0.0810\n",
      "Epoch 506/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 3.1008e-05 - accuracy: 0.1512 - val_loss: 0.1316 - val_accuracy: 0.0571\n",
      "Epoch 507/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 3.4909e-05 - accuracy: 0.1448 - val_loss: 0.1317 - val_accuracy: 0.0429\n",
      "Epoch 508/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.9801e-05 - accuracy: 0.1528 - val_loss: 0.1323 - val_accuracy: 0.0857\n",
      "Epoch 509/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.2064e-05 - accuracy: 0.1523 - val_loss: 0.1307 - val_accuracy: 0.0667\n",
      "Epoch 510/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.0764e-05 - accuracy: 0.1538 - val_loss: 0.1315 - val_accuracy: 0.0905\n",
      "Epoch 511/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 3.0557e-05 - accuracy: 0.1560 - val_loss: 0.1311 - val_accuracy: 0.0667\n",
      "Epoch 512/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.2806e-05 - accuracy: 0.1496 - val_loss: 0.1316 - val_accuracy: 0.0714\n",
      "Epoch 513/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.8966e-05 - accuracy: 0.1475 - val_loss: 0.1308 - val_accuracy: 0.0810\n",
      "Epoch 514/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.9828e-05 - accuracy: 0.1607 - val_loss: 0.1299 - val_accuracy: 0.0810\n",
      "Epoch 515/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.8878e-05 - accuracy: 0.1491 - val_loss: 0.1316 - val_accuracy: 0.0381\n",
      "Epoch 516/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.8954e-05 - accuracy: 0.1480 - val_loss: 0.1312 - val_accuracy: 0.0810\n",
      "Epoch 517/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7947e-05 - accuracy: 0.1528 - val_loss: 0.1319 - val_accuracy: 0.0857\n",
      "Epoch 518/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.7792e-05 - accuracy: 0.1560 - val_loss: 0.1320 - val_accuracy: 0.0810\n",
      "Epoch 519/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.8755e-05 - accuracy: 0.1517 - val_loss: 0.1295 - val_accuracy: 0.0714\n",
      "Epoch 520/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 3.2187e-05 - accuracy: 0.1533 - val_loss: 0.1294 - val_accuracy: 0.0905\n",
      "Epoch 521/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.9314e-05 - accuracy: 0.1432 - val_loss: 0.1352 - val_accuracy: 0.0571\n",
      "Epoch 522/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.0518e-05 - accuracy: 0.1528 - val_loss: 0.1307 - val_accuracy: 0.0619\n",
      "Epoch 523/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7812e-05 - accuracy: 0.1533 - val_loss: 0.1308 - val_accuracy: 0.0952\n",
      "Epoch 524/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.9982e-05 - accuracy: 0.1623 - val_loss: 0.1310 - val_accuracy: 0.0571\n",
      "Epoch 525/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.7188e-05 - accuracy: 0.1639 - val_loss: 0.1310 - val_accuracy: 0.0857\n",
      "Epoch 526/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.8706e-05 - accuracy: 0.1570 - val_loss: 0.1325 - val_accuracy: 0.0857\n",
      "Epoch 527/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 3.9162e-05 - accuracy: 0.1501 - val_loss: 0.1292 - val_accuracy: 0.0857\n",
      "Epoch 528/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.9882e-05 - accuracy: 0.1496 - val_loss: 0.1302 - val_accuracy: 0.0857\n",
      "Epoch 529/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.8983e-05 - accuracy: 0.1607 - val_loss: 0.1292 - val_accuracy: 0.0667\n",
      "Epoch 530/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7837e-05 - accuracy: 0.1560 - val_loss: 0.1298 - val_accuracy: 0.0762\n",
      "Epoch 531/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.1213e-05 - accuracy: 0.1485 - val_loss: 0.1283 - val_accuracy: 0.0762\n",
      "Epoch 532/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7404e-05 - accuracy: 0.1560 - val_loss: 0.1321 - val_accuracy: 0.0714\n",
      "Epoch 533/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7533e-05 - accuracy: 0.1597 - val_loss: 0.1297 - val_accuracy: 0.0714\n",
      "Epoch 534/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7017e-05 - accuracy: 0.1554 - val_loss: 0.1293 - val_accuracy: 0.0714\n",
      "Epoch 535/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.3062e-05 - accuracy: 0.1480 - val_loss: 0.1304 - val_accuracy: 0.0714\n",
      "Epoch 536/800\n",
      "59/59 [==============================] - 12s 197ms/step - loss: 3.3069e-05 - accuracy: 0.1565 - val_loss: 0.1295 - val_accuracy: 0.0857\n",
      "Epoch 537/800\n",
      "59/59 [==============================] - 13s 225ms/step - loss: 3.0958e-05 - accuracy: 0.1570 - val_loss: 0.1311 - val_accuracy: 0.0619\n",
      "Epoch 538/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 2.8798e-05 - accuracy: 0.1544 - val_loss: 0.1279 - val_accuracy: 0.0429\n",
      "Epoch 539/800\n",
      "59/59 [==============================] - 15s 247ms/step - loss: 2.9072e-05 - accuracy: 0.1570 - val_loss: 0.1281 - val_accuracy: 0.0762\n",
      "Epoch 540/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.8663e-05 - accuracy: 0.1549 - val_loss: 0.1310 - val_accuracy: 0.0810\n",
      "Epoch 541/800\n",
      "59/59 [==============================] - 14s 236ms/step - loss: 2.9015e-05 - accuracy: 0.1592 - val_loss: 0.1318 - val_accuracy: 0.0667\n",
      "Epoch 542/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.8051e-05 - accuracy: 0.1538 - val_loss: 0.1300 - val_accuracy: 0.0667\n",
      "Epoch 543/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.7478e-05 - accuracy: 0.1607 - val_loss: 0.1295 - val_accuracy: 0.0810\n",
      "Epoch 544/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.9257e-05 - accuracy: 0.1597 - val_loss: 0.1309 - val_accuracy: 0.0857\n",
      "Epoch 545/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.9375e-05 - accuracy: 0.1613 - val_loss: 0.1278 - val_accuracy: 0.0667\n",
      "Epoch 546/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.8939e-05 - accuracy: 0.1570 - val_loss: 0.1293 - val_accuracy: 0.0667\n",
      "Epoch 547/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.6719e-05 - accuracy: 0.1533 - val_loss: 0.1276 - val_accuracy: 0.0476\n",
      "Epoch 548/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.7341e-05 - accuracy: 0.1570 - val_loss: 0.1301 - val_accuracy: 0.0714\n",
      "Epoch 549/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.9882e-05 - accuracy: 0.1761 - val_loss: 0.1291 - val_accuracy: 0.0762\n",
      "Epoch 550/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.8527e-05 - accuracy: 0.1538 - val_loss: 0.1295 - val_accuracy: 0.0905\n",
      "Epoch 551/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7749e-05 - accuracy: 0.1618 - val_loss: 0.1286 - val_accuracy: 0.0571\n",
      "Epoch 552/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.7147e-05 - accuracy: 0.1623 - val_loss: 0.1294 - val_accuracy: 0.0571\n",
      "Epoch 553/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.7210e-05 - accuracy: 0.1560 - val_loss: 0.1293 - val_accuracy: 0.0714\n",
      "Epoch 554/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.9966e-05 - accuracy: 0.1671 - val_loss: 0.1320 - val_accuracy: 0.0714\n",
      "Epoch 555/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 3.3377e-05 - accuracy: 0.1560 - val_loss: 0.1300 - val_accuracy: 0.0810\n",
      "Epoch 556/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.7760e-05 - accuracy: 0.1576 - val_loss: 0.1306 - val_accuracy: 0.0762\n",
      "Epoch 557/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7007e-05 - accuracy: 0.1719 - val_loss: 0.1289 - val_accuracy: 0.0905\n",
      "Epoch 558/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.5654e-05 - accuracy: 0.1698 - val_loss: 0.1297 - val_accuracy: 0.0714\n",
      "Epoch 559/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7500e-05 - accuracy: 0.1645 - val_loss: 0.1316 - val_accuracy: 0.0762\n",
      "Epoch 560/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.5866e-05 - accuracy: 0.1639 - val_loss: 0.1304 - val_accuracy: 0.0714\n",
      "Epoch 561/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.7545e-05 - accuracy: 0.1629 - val_loss: 0.1270 - val_accuracy: 0.0667\n",
      "Epoch 562/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 3.1388e-05 - accuracy: 0.1618 - val_loss: 0.1305 - val_accuracy: 0.0524\n",
      "Epoch 563/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7643e-05 - accuracy: 0.1523 - val_loss: 0.1273 - val_accuracy: 0.0905\n",
      "Epoch 564/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.6292e-05 - accuracy: 0.1639 - val_loss: 0.1298 - val_accuracy: 0.0619\n",
      "Epoch 565/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.7593e-05 - accuracy: 0.1645 - val_loss: 0.1280 - val_accuracy: 0.0714\n",
      "Epoch 566/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.7837e-05 - accuracy: 0.1676 - val_loss: 0.1275 - val_accuracy: 0.0714\n",
      "Epoch 567/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.6868e-05 - accuracy: 0.1650 - val_loss: 0.1296 - val_accuracy: 0.0810\n",
      "Epoch 568/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.5300e-05 - accuracy: 0.1597 - val_loss: 0.1283 - val_accuracy: 0.0714\n",
      "Epoch 569/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.6965e-05 - accuracy: 0.1708 - val_loss: 0.1301 - val_accuracy: 0.0619\n",
      "Epoch 570/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.8454e-05 - accuracy: 0.1655 - val_loss: 0.1298 - val_accuracy: 0.0619\n",
      "Epoch 571/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 4.3795e-05 - accuracy: 0.1485 - val_loss: 0.1319 - val_accuracy: 0.0667\n",
      "Epoch 572/800\n",
      "59/59 [==============================] - 14s 229ms/step - loss: 9.2725e-05 - accuracy: 0.1273 - val_loss: 0.1260 - val_accuracy: 0.0714\n",
      "Epoch 573/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 6.6411e-05 - accuracy: 0.1406 - val_loss: 0.1387 - val_accuracy: 0.0714\n",
      "Epoch 574/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 3.1268e-05 - accuracy: 0.1570 - val_loss: 0.1330 - val_accuracy: 0.0905\n",
      "Epoch 575/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.7211e-05 - accuracy: 0.1613 - val_loss: 0.1304 - val_accuracy: 0.0524\n",
      "Epoch 576/800\n",
      "59/59 [==============================] - 15s 250ms/step - loss: 2.5171e-05 - accuracy: 0.1586 - val_loss: 0.1300 - val_accuracy: 0.0619\n",
      "Epoch 577/800\n",
      "59/59 [==============================] - 14s 246ms/step - loss: 2.4579e-05 - accuracy: 0.1592 - val_loss: 0.1307 - val_accuracy: 0.0619\n",
      "Epoch 578/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.5166e-05 - accuracy: 0.1639 - val_loss: 0.1289 - val_accuracy: 0.0571\n",
      "Epoch 579/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.5630e-05 - accuracy: 0.1549 - val_loss: 0.1290 - val_accuracy: 0.0714\n",
      "Epoch 580/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.5635e-05 - accuracy: 0.1581 - val_loss: 0.1280 - val_accuracy: 0.0619\n",
      "Epoch 581/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.4851e-05 - accuracy: 0.1724 - val_loss: 0.1286 - val_accuracy: 0.0667\n",
      "Epoch 582/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.5232e-05 - accuracy: 0.1671 - val_loss: 0.1296 - val_accuracy: 0.0714\n",
      "Epoch 583/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 2.7255e-05 - accuracy: 0.1507 - val_loss: 0.1274 - val_accuracy: 0.0619\n",
      "Epoch 584/800\n",
      "59/59 [==============================] - 13s 226ms/step - loss: 2.7429e-05 - accuracy: 0.1745 - val_loss: 0.1286 - val_accuracy: 0.0714\n",
      "Epoch 585/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 2.6964e-05 - accuracy: 0.1592 - val_loss: 0.1282 - val_accuracy: 0.0762\n",
      "Epoch 586/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.4672e-05 - accuracy: 0.1581 - val_loss: 0.1291 - val_accuracy: 0.0762\n",
      "Epoch 587/800\n",
      "59/59 [==============================] - 13s 228ms/step - loss: 2.5394e-05 - accuracy: 0.1613 - val_loss: 0.1290 - val_accuracy: 0.0714\n",
      "Epoch 588/800\n",
      "59/59 [==============================] - 15s 256ms/step - loss: 2.5733e-05 - accuracy: 0.1607 - val_loss: 0.1263 - val_accuracy: 0.0619\n",
      "Epoch 589/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.5864e-05 - accuracy: 0.1629 - val_loss: 0.1308 - val_accuracy: 0.0429\n",
      "Epoch 590/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.4538e-05 - accuracy: 0.1597 - val_loss: 0.1283 - val_accuracy: 0.0619\n",
      "Epoch 591/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.3790e-05 - accuracy: 0.1692 - val_loss: 0.1280 - val_accuracy: 0.0619\n",
      "Epoch 592/800\n",
      "59/59 [==============================] - 11s 191ms/step - loss: 2.4800e-05 - accuracy: 0.1613 - val_loss: 0.1291 - val_accuracy: 0.0667\n",
      "Epoch 593/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.4749e-05 - accuracy: 0.1666 - val_loss: 0.1279 - val_accuracy: 0.0762\n",
      "Epoch 594/800\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 2.5749e-05 - accuracy: 0.1708 - val_loss: 0.1252 - val_accuracy: 0.0667\n",
      "Epoch 595/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.9507e-05 - accuracy: 0.1671 - val_loss: 0.1306 - val_accuracy: 0.0571\n",
      "Epoch 596/800\n",
      "59/59 [==============================] - 11s 183ms/step - loss: 4.3262e-05 - accuracy: 0.1538 - val_loss: 0.1284 - val_accuracy: 0.0619\n",
      "Epoch 597/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 2.8426e-05 - accuracy: 0.1592 - val_loss: 0.1293 - val_accuracy: 0.0810\n",
      "Epoch 598/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.6297e-05 - accuracy: 0.1772 - val_loss: 0.1296 - val_accuracy: 0.0333\n",
      "Epoch 599/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 2.4534e-05 - accuracy: 0.1650 - val_loss: 0.1292 - val_accuracy: 0.0714\n",
      "Epoch 600/800\n",
      "59/59 [==============================] - 11s 179ms/step - loss: 2.3666e-05 - accuracy: 0.1671 - val_loss: 0.1296 - val_accuracy: 0.0619\n",
      "Epoch 601/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 2.7683e-05 - accuracy: 0.1576 - val_loss: 0.1282 - val_accuracy: 0.0476\n",
      "Epoch 602/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 2.7541e-05 - accuracy: 0.1751 - val_loss: 0.1304 - val_accuracy: 0.0762\n",
      "Epoch 603/800\n",
      "59/59 [==============================] - 11s 180ms/step - loss: 2.7722e-05 - accuracy: 0.1719 - val_loss: 0.1311 - val_accuracy: 0.0381\n",
      "Epoch 604/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 2.5840e-05 - accuracy: 0.1607 - val_loss: 0.1288 - val_accuracy: 0.0762\n",
      "Epoch 605/800\n",
      "59/59 [==============================] - 11s 184ms/step - loss: 2.5698e-05 - accuracy: 0.1655 - val_loss: 0.1280 - val_accuracy: 0.0667\n",
      "Epoch 606/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.4030e-05 - accuracy: 0.1666 - val_loss: 0.1287 - val_accuracy: 0.0714\n",
      "Epoch 607/800\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 3.3205e-05 - accuracy: 0.1687 - val_loss: 0.1258 - val_accuracy: 0.0714\n",
      "Epoch 608/800\n",
      "59/59 [==============================] - 11s 185ms/step - loss: 2.9873e-05 - accuracy: 0.1623 - val_loss: 0.1288 - val_accuracy: 0.0667\n",
      "Epoch 609/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 2.3499e-05 - accuracy: 0.1708 - val_loss: 0.1294 - val_accuracy: 0.0667\n",
      "Epoch 610/800\n",
      "59/59 [==============================] - 11s 194ms/step - loss: 2.3353e-05 - accuracy: 0.1719 - val_loss: 0.1291 - val_accuracy: 0.0714\n",
      "Epoch 611/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.3337e-05 - accuracy: 0.1703 - val_loss: 0.1291 - val_accuracy: 0.0667\n",
      "Epoch 612/800\n",
      "59/59 [==============================] - 11s 194ms/step - loss: 2.3461e-05 - accuracy: 0.1692 - val_loss: 0.1289 - val_accuracy: 0.0619\n",
      "Epoch 613/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 2.4397e-05 - accuracy: 0.1692 - val_loss: 0.1285 - val_accuracy: 0.0524\n",
      "Epoch 614/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 2.4465e-05 - accuracy: 0.1782 - val_loss: 0.1277 - val_accuracy: 0.0762\n",
      "Epoch 615/800\n",
      "59/59 [==============================] - 16s 265ms/step - loss: 2.4641e-05 - accuracy: 0.1660 - val_loss: 0.1271 - val_accuracy: 0.0619\n",
      "Epoch 616/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.5557e-05 - accuracy: 0.1756 - val_loss: 0.1278 - val_accuracy: 0.0714\n",
      "Epoch 617/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 2.4554e-05 - accuracy: 0.1666 - val_loss: 0.1288 - val_accuracy: 0.0476\n",
      "Epoch 618/800\n",
      "59/59 [==============================] - 12s 210ms/step - loss: 2.4205e-05 - accuracy: 0.1655 - val_loss: 0.1282 - val_accuracy: 0.0714\n",
      "Epoch 619/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.3943e-05 - accuracy: 0.1735 - val_loss: 0.1296 - val_accuracy: 0.0667\n",
      "Epoch 620/800\n",
      "59/59 [==============================] - 12s 212ms/step - loss: 2.6031e-05 - accuracy: 0.1767 - val_loss: 0.1293 - val_accuracy: 0.0524\n",
      "Epoch 621/800\n",
      "59/59 [==============================] - 12s 212ms/step - loss: 2.5298e-05 - accuracy: 0.1698 - val_loss: 0.1282 - val_accuracy: 0.0571\n",
      "Epoch 622/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.5691e-05 - accuracy: 0.1660 - val_loss: 0.1284 - val_accuracy: 0.0667\n",
      "Epoch 623/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.3549e-05 - accuracy: 0.1798 - val_loss: 0.1275 - val_accuracy: 0.0619\n",
      "Epoch 624/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.8073e-05 - accuracy: 0.1682 - val_loss: 0.1256 - val_accuracy: 0.0619\n",
      "Epoch 625/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.5772e-05 - accuracy: 0.1703 - val_loss: 0.1295 - val_accuracy: 0.0714\n",
      "Epoch 626/800\n",
      "59/59 [==============================] - 12s 206ms/step - loss: 2.5919e-05 - accuracy: 0.1820 - val_loss: 0.1271 - val_accuracy: 0.0667\n",
      "Epoch 627/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 3.0276e-05 - accuracy: 0.1719 - val_loss: 0.1302 - val_accuracy: 0.0667\n",
      "Epoch 628/800\n",
      "59/59 [==============================] - 14s 239ms/step - loss: 2.6423e-05 - accuracy: 0.1698 - val_loss: 0.1262 - val_accuracy: 0.0619\n",
      "Epoch 629/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.5127e-05 - accuracy: 0.1751 - val_loss: 0.1275 - val_accuracy: 0.0714\n",
      "Epoch 630/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.9995e-05 - accuracy: 0.1788 - val_loss: 0.1282 - val_accuracy: 0.0619\n",
      "Epoch 631/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.8209e-05 - accuracy: 0.1729 - val_loss: 0.1265 - val_accuracy: 0.0810\n",
      "Epoch 632/800\n",
      "59/59 [==============================] - 12s 205ms/step - loss: 2.6064e-05 - accuracy: 0.1735 - val_loss: 0.1272 - val_accuracy: 0.0667\n",
      "Epoch 633/800\n",
      "59/59 [==============================] - 12s 202ms/step - loss: 2.7993e-05 - accuracy: 0.1857 - val_loss: 0.1240 - val_accuracy: 0.0667\n",
      "Epoch 634/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.6915e-05 - accuracy: 0.1698 - val_loss: 0.1272 - val_accuracy: 0.0524\n",
      "Epoch 635/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.3825e-05 - accuracy: 0.1793 - val_loss: 0.1268 - val_accuracy: 0.0619\n",
      "Epoch 636/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.6679e-05 - accuracy: 0.1698 - val_loss: 0.1258 - val_accuracy: 0.0429\n",
      "Epoch 637/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.5820e-05 - accuracy: 0.1767 - val_loss: 0.1269 - val_accuracy: 0.0667\n",
      "Epoch 638/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.8030e-05 - accuracy: 0.1682 - val_loss: 0.1274 - val_accuracy: 0.0714\n",
      "Epoch 639/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.4744e-05 - accuracy: 0.1671 - val_loss: 0.1275 - val_accuracy: 0.0714\n",
      "Epoch 640/800\n",
      "59/59 [==============================] - 12s 203ms/step - loss: 2.2904e-05 - accuracy: 0.1836 - val_loss: 0.1281 - val_accuracy: 0.0619\n",
      "Epoch 641/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 2.3030e-05 - accuracy: 0.1714 - val_loss: 0.1268 - val_accuracy: 0.0619\n",
      "Epoch 642/800\n",
      "59/59 [==============================] - 13s 216ms/step - loss: 2.3728e-05 - accuracy: 0.1889 - val_loss: 0.1287 - val_accuracy: 0.0667\n",
      "Epoch 643/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.4631e-05 - accuracy: 0.1692 - val_loss: 0.1262 - val_accuracy: 0.0667\n",
      "Epoch 644/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.4556e-05 - accuracy: 0.1714 - val_loss: 0.1260 - val_accuracy: 0.0714\n",
      "Epoch 645/800\n",
      "59/59 [==============================] - 12s 208ms/step - loss: 2.3520e-05 - accuracy: 0.1703 - val_loss: 0.1274 - val_accuracy: 0.0571\n",
      "Epoch 646/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.5298e-05 - accuracy: 0.1724 - val_loss: 0.1242 - val_accuracy: 0.0333\n",
      "Epoch 647/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 2.3413e-05 - accuracy: 0.1836 - val_loss: 0.1269 - val_accuracy: 0.0571\n",
      "Epoch 648/800\n",
      "59/59 [==============================] - 13s 217ms/step - loss: 2.3344e-05 - accuracy: 0.1820 - val_loss: 0.1263 - val_accuracy: 0.0810\n",
      "Epoch 649/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 2.4659e-05 - accuracy: 0.1772 - val_loss: 0.1254 - val_accuracy: 0.0619\n",
      "Epoch 650/800\n",
      "59/59 [==============================] - 12s 209ms/step - loss: 2.3825e-05 - accuracy: 0.1788 - val_loss: 0.1265 - val_accuracy: 0.0619\n",
      "Epoch 651/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.3632e-05 - accuracy: 0.1836 - val_loss: 0.1261 - val_accuracy: 0.0524\n",
      "Epoch 652/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 2.5423e-05 - accuracy: 0.1841 - val_loss: 0.1310 - val_accuracy: 0.0571\n",
      "Epoch 653/800\n",
      "59/59 [==============================] - 15s 256ms/step - loss: 2.5010e-05 - accuracy: 0.1655 - val_loss: 0.1246 - val_accuracy: 0.0524\n",
      "Epoch 654/800\n",
      "59/59 [==============================] - 14s 238ms/step - loss: 2.6325e-05 - accuracy: 0.1719 - val_loss: 0.1224 - val_accuracy: 0.0571\n",
      "Epoch 655/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.5258e-05 - accuracy: 0.1767 - val_loss: 0.1263 - val_accuracy: 0.0571\n",
      "Epoch 656/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 3.7559e-05 - accuracy: 0.1729 - val_loss: 0.1253 - val_accuracy: 0.0667\n",
      "Epoch 657/800\n",
      "59/59 [==============================] - 14s 239ms/step - loss: 3.3218e-05 - accuracy: 0.1719 - val_loss: 0.1271 - val_accuracy: 0.0714\n",
      "Epoch 658/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 2.6048e-05 - accuracy: 0.1687 - val_loss: 0.1288 - val_accuracy: 0.0667\n",
      "Epoch 659/800\n",
      "59/59 [==============================] - 12s 207ms/step - loss: 2.5329e-05 - accuracy: 0.1714 - val_loss: 0.1285 - val_accuracy: 0.0667\n",
      "Epoch 660/800\n",
      "59/59 [==============================] - 14s 236ms/step - loss: 2.3410e-05 - accuracy: 0.1740 - val_loss: 0.1265 - val_accuracy: 0.0667\n",
      "Epoch 661/800\n",
      "59/59 [==============================] - 11s 193ms/step - loss: 2.2715e-05 - accuracy: 0.1714 - val_loss: 0.1261 - val_accuracy: 0.0524\n",
      "Epoch 662/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.1811e-05 - accuracy: 0.1809 - val_loss: 0.1273 - val_accuracy: 0.0524\n",
      "Epoch 663/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.3112e-05 - accuracy: 0.1809 - val_loss: 0.1268 - val_accuracy: 0.0619\n",
      "Epoch 664/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2335e-05 - accuracy: 0.1756 - val_loss: 0.1255 - val_accuracy: 0.0571\n",
      "Epoch 665/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2827e-05 - accuracy: 0.1846 - val_loss: 0.1278 - val_accuracy: 0.0619\n",
      "Epoch 666/800\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 2.9729e-05 - accuracy: 0.1708 - val_loss: 0.1278 - val_accuracy: 0.0619\n",
      "Epoch 667/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 4.2838e-05 - accuracy: 0.1671 - val_loss: 0.1296 - val_accuracy: 0.0619\n",
      "Epoch 668/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.6534e-05 - accuracy: 0.1729 - val_loss: 0.1227 - val_accuracy: 0.0571\n",
      "Epoch 669/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3218e-05 - accuracy: 0.1798 - val_loss: 0.1268 - val_accuracy: 0.0524\n",
      "Epoch 670/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2755e-05 - accuracy: 0.1841 - val_loss: 0.1255 - val_accuracy: 0.0619\n",
      "Epoch 671/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3519e-05 - accuracy: 0.1867 - val_loss: 0.1261 - val_accuracy: 0.0619\n",
      "Epoch 672/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.4831e-05 - accuracy: 0.1830 - val_loss: 0.1256 - val_accuracy: 0.0571\n",
      "Epoch 673/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2190e-05 - accuracy: 0.1841 - val_loss: 0.1252 - val_accuracy: 0.0571\n",
      "Epoch 674/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.1659e-05 - accuracy: 0.1676 - val_loss: 0.1255 - val_accuracy: 0.0524\n",
      "Epoch 675/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2104e-05 - accuracy: 0.1846 - val_loss: 0.1253 - val_accuracy: 0.0524\n",
      "Epoch 676/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.1883e-05 - accuracy: 0.1814 - val_loss: 0.1259 - val_accuracy: 0.0571\n",
      "Epoch 677/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.1809e-05 - accuracy: 0.1936 - val_loss: 0.1238 - val_accuracy: 0.0524\n",
      "Epoch 678/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2821e-05 - accuracy: 0.1825 - val_loss: 0.1253 - val_accuracy: 0.0524\n",
      "Epoch 679/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3952e-05 - accuracy: 0.1846 - val_loss: 0.1246 - val_accuracy: 0.0619\n",
      "Epoch 680/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.4630e-05 - accuracy: 0.1767 - val_loss: 0.1248 - val_accuracy: 0.0571\n",
      "Epoch 681/800\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 2.2610e-05 - accuracy: 0.1836 - val_loss: 0.1257 - val_accuracy: 0.0476\n",
      "Epoch 682/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2898e-05 - accuracy: 0.1714 - val_loss: 0.1238 - val_accuracy: 0.0571\n",
      "Epoch 683/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.3576e-05 - accuracy: 0.1820 - val_loss: 0.1224 - val_accuracy: 0.0524\n",
      "Epoch 684/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.3822e-05 - accuracy: 0.1788 - val_loss: 0.1239 - val_accuracy: 0.0619\n",
      "Epoch 685/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.3425e-05 - accuracy: 0.1836 - val_loss: 0.1244 - val_accuracy: 0.0524\n",
      "Epoch 686/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2369e-05 - accuracy: 0.1936 - val_loss: 0.1246 - val_accuracy: 0.0667\n",
      "Epoch 687/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3034e-05 - accuracy: 0.1793 - val_loss: 0.1240 - val_accuracy: 0.0429\n",
      "Epoch 688/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3283e-05 - accuracy: 0.1915 - val_loss: 0.1242 - val_accuracy: 0.0429\n",
      "Epoch 689/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.3179e-05 - accuracy: 0.1735 - val_loss: 0.1230 - val_accuracy: 0.0571\n",
      "Epoch 690/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.3382e-05 - accuracy: 0.1714 - val_loss: 0.1232 - val_accuracy: 0.0524\n",
      "Epoch 691/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.1916e-05 - accuracy: 0.1947 - val_loss: 0.1252 - val_accuracy: 0.0524\n",
      "Epoch 692/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.1560e-05 - accuracy: 0.2032 - val_loss: 0.1240 - val_accuracy: 0.0524\n",
      "Epoch 693/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2113e-05 - accuracy: 0.1798 - val_loss: 0.1212 - val_accuracy: 0.0524\n",
      "Epoch 694/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3823e-05 - accuracy: 0.1841 - val_loss: 0.1262 - val_accuracy: 0.0524\n",
      "Epoch 695/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.4301e-05 - accuracy: 0.1841 - val_loss: 0.1242 - val_accuracy: 0.0524\n",
      "Epoch 696/800\n",
      "59/59 [==============================] - 11s 191ms/step - loss: 2.3011e-05 - accuracy: 0.1767 - val_loss: 0.1227 - val_accuracy: 0.0619\n",
      "Epoch 697/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.3140e-05 - accuracy: 0.1979 - val_loss: 0.1267 - val_accuracy: 0.0619\n",
      "Epoch 698/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.2974e-05 - accuracy: 0.1761 - val_loss: 0.1259 - val_accuracy: 0.0619\n",
      "Epoch 699/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3213e-05 - accuracy: 0.1836 - val_loss: 0.1238 - val_accuracy: 0.0524\n",
      "Epoch 700/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.5718e-05 - accuracy: 0.1767 - val_loss: 0.1246 - val_accuracy: 0.0571\n",
      "Epoch 701/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.6429e-05 - accuracy: 0.1814 - val_loss: 0.1245 - val_accuracy: 0.0714\n",
      "Epoch 702/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2522e-05 - accuracy: 0.1862 - val_loss: 0.1246 - val_accuracy: 0.0619\n",
      "Epoch 703/800\n",
      "59/59 [==============================] - 11s 185ms/step - loss: 2.4849e-05 - accuracy: 0.1793 - val_loss: 0.1258 - val_accuracy: 0.0667\n",
      "Epoch 704/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.4162e-05 - accuracy: 0.1788 - val_loss: 0.1252 - val_accuracy: 0.0524\n",
      "Epoch 705/800\n",
      "59/59 [==============================] - 11s 185ms/step - loss: 2.3626e-05 - accuracy: 0.1862 - val_loss: 0.1250 - val_accuracy: 0.0429\n",
      "Epoch 706/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2527e-05 - accuracy: 0.1910 - val_loss: 0.1242 - val_accuracy: 0.0714\n",
      "Epoch 707/800\n",
      "59/59 [==============================] - 17s 283ms/step - loss: 2.1696e-05 - accuracy: 0.1719 - val_loss: 0.1261 - val_accuracy: 0.0571\n",
      "Epoch 708/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.1604e-05 - accuracy: 0.1915 - val_loss: 0.1249 - val_accuracy: 0.0524\n",
      "Epoch 709/800\n",
      "59/59 [==============================] - 12s 211ms/step - loss: 2.1507e-05 - accuracy: 0.1830 - val_loss: 0.1244 - val_accuracy: 0.0619\n",
      "Epoch 710/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.1250e-05 - accuracy: 0.1873 - val_loss: 0.1247 - val_accuracy: 0.0571\n",
      "Epoch 711/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3250e-05 - accuracy: 0.1793 - val_loss: 0.1233 - val_accuracy: 0.0476\n",
      "Epoch 712/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.4724e-05 - accuracy: 0.1836 - val_loss: 0.1245 - val_accuracy: 0.0619\n",
      "Epoch 713/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.9626e-05 - accuracy: 0.1735 - val_loss: 0.1243 - val_accuracy: 0.0476\n",
      "Epoch 714/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.5100e-05 - accuracy: 0.1788 - val_loss: 0.1230 - val_accuracy: 0.0524\n",
      "Epoch 715/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.4554e-05 - accuracy: 0.1825 - val_loss: 0.1243 - val_accuracy: 0.0476\n",
      "Epoch 716/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3759e-05 - accuracy: 0.1772 - val_loss: 0.1232 - val_accuracy: 0.0476\n",
      "Epoch 717/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.2783e-05 - accuracy: 0.1899 - val_loss: 0.1230 - val_accuracy: 0.0524\n",
      "Epoch 718/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2169e-05 - accuracy: 0.1756 - val_loss: 0.1209 - val_accuracy: 0.0381\n",
      "Epoch 719/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.1415e-05 - accuracy: 0.1841 - val_loss: 0.1229 - val_accuracy: 0.0524\n",
      "Epoch 720/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.4145e-05 - accuracy: 0.1814 - val_loss: 0.1262 - val_accuracy: 0.0619\n",
      "Epoch 721/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.3300e-05 - accuracy: 0.1830 - val_loss: 0.1233 - val_accuracy: 0.0524\n",
      "Epoch 722/800\n",
      "59/59 [==============================] - 11s 190ms/step - loss: 2.1554e-05 - accuracy: 0.1798 - val_loss: 0.1222 - val_accuracy: 0.0429\n",
      "Epoch 723/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.1004e-05 - accuracy: 0.1910 - val_loss: 0.1232 - val_accuracy: 0.0524\n",
      "Epoch 724/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.1224e-05 - accuracy: 0.1857 - val_loss: 0.1233 - val_accuracy: 0.0524\n",
      "Epoch 725/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.1877e-05 - accuracy: 0.1968 - val_loss: 0.1217 - val_accuracy: 0.0524\n",
      "Epoch 726/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3021e-05 - accuracy: 0.1782 - val_loss: 0.1221 - val_accuracy: 0.0524\n",
      "Epoch 727/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.0840e-05 - accuracy: 0.1857 - val_loss: 0.1222 - val_accuracy: 0.0524\n",
      "Epoch 728/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2063e-05 - accuracy: 0.1862 - val_loss: 0.1217 - val_accuracy: 0.0524\n",
      "Epoch 729/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.2982e-05 - accuracy: 0.1889 - val_loss: 0.1220 - val_accuracy: 0.0571\n",
      "Epoch 730/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.5466e-05 - accuracy: 0.1809 - val_loss: 0.1220 - val_accuracy: 0.0381\n",
      "Epoch 731/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.2000e-05 - accuracy: 0.1804 - val_loss: 0.1216 - val_accuracy: 0.0286\n",
      "Epoch 732/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.6979e-05 - accuracy: 0.1905 - val_loss: 0.1239 - val_accuracy: 0.0476\n",
      "Epoch 733/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.5253e-05 - accuracy: 0.1841 - val_loss: 0.1275 - val_accuracy: 0.0429\n",
      "Epoch 734/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 3.0770e-05 - accuracy: 0.1745 - val_loss: 0.1264 - val_accuracy: 0.0381\n",
      "Epoch 735/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.3258e-05 - accuracy: 0.1958 - val_loss: 0.1242 - val_accuracy: 0.0571\n",
      "Epoch 736/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.0876e-05 - accuracy: 0.1873 - val_loss: 0.1236 - val_accuracy: 0.0381\n",
      "Epoch 737/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.0254e-05 - accuracy: 0.1936 - val_loss: 0.1233 - val_accuracy: 0.0571\n",
      "Epoch 738/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.1852e-05 - accuracy: 0.1830 - val_loss: 0.1237 - val_accuracy: 0.0619\n",
      "Epoch 739/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.3605e-05 - accuracy: 0.1936 - val_loss: 0.1231 - val_accuracy: 0.0476\n",
      "Epoch 740/800\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 2.2537e-05 - accuracy: 0.1936 - val_loss: 0.1237 - val_accuracy: 0.0476\n",
      "Epoch 741/800\n",
      "59/59 [==============================] - 11s 189ms/step - loss: 2.1163e-05 - accuracy: 0.1963 - val_loss: 0.1236 - val_accuracy: 0.0381\n",
      "Epoch 742/800\n",
      "59/59 [==============================] - 11s 188ms/step - loss: 2.0976e-05 - accuracy: 0.1958 - val_loss: 0.1216 - val_accuracy: 0.0381\n",
      "Epoch 743/800\n",
      "59/59 [==============================] - 14s 245ms/step - loss: 2.0674e-05 - accuracy: 0.1942 - val_loss: 0.1223 - val_accuracy: 0.0476\n",
      "Epoch 744/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 2.3434e-05 - accuracy: 0.1947 - val_loss: 0.1240 - val_accuracy: 0.0476\n",
      "Epoch 745/800\n",
      "59/59 [==============================] - 17s 290ms/step - loss: 2.5903e-05 - accuracy: 0.1740 - val_loss: 0.1183 - val_accuracy: 0.0524\n",
      "Epoch 746/800\n",
      "59/59 [==============================] - 13s 216ms/step - loss: 2.1641e-05 - accuracy: 0.1841 - val_loss: 0.1230 - val_accuracy: 0.0571\n",
      "Epoch 747/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 2.0906e-05 - accuracy: 0.1846 - val_loss: 0.1231 - val_accuracy: 0.0524\n",
      "Epoch 748/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 2.1563e-05 - accuracy: 0.1915 - val_loss: 0.1243 - val_accuracy: 0.0714\n",
      "Epoch 749/800\n",
      "59/59 [==============================] - 13s 226ms/step - loss: 2.2022e-05 - accuracy: 0.1905 - val_loss: 0.1217 - val_accuracy: 0.0476\n",
      "Epoch 750/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 2.2043e-05 - accuracy: 0.1735 - val_loss: 0.1208 - val_accuracy: 0.0571\n",
      "Epoch 751/800\n",
      "59/59 [==============================] - 15s 254ms/step - loss: 2.1015e-05 - accuracy: 0.1862 - val_loss: 0.1234 - val_accuracy: 0.0571\n",
      "Epoch 752/800\n",
      "59/59 [==============================] - 15s 246ms/step - loss: 2.0071e-05 - accuracy: 0.1857 - val_loss: 0.1223 - val_accuracy: 0.0476\n",
      "Epoch 753/800\n",
      "59/59 [==============================] - 14s 246ms/step - loss: 2.0625e-05 - accuracy: 0.1830 - val_loss: 0.1228 - val_accuracy: 0.0571\n",
      "Epoch 754/800\n",
      "59/59 [==============================] - 15s 246ms/step - loss: 2.2548e-05 - accuracy: 0.1889 - val_loss: 0.1220 - val_accuracy: 0.0476\n",
      "Epoch 755/800\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 2.4996e-05 - accuracy: 0.1851 - val_loss: 0.1292 - val_accuracy: 0.0524\n",
      "Epoch 756/800\n",
      "59/59 [==============================] - 15s 247ms/step - loss: 2.4044e-05 - accuracy: 0.1804 - val_loss: 0.1252 - val_accuracy: 0.0524\n",
      "Epoch 757/800\n",
      "59/59 [==============================] - 14s 243ms/step - loss: 2.1704e-05 - accuracy: 0.1873 - val_loss: 0.1213 - val_accuracy: 0.0476\n",
      "Epoch 758/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 2.2811e-05 - accuracy: 0.1809 - val_loss: 0.1203 - val_accuracy: 0.0524\n",
      "Epoch 759/800\n",
      "59/59 [==============================] - 13s 229ms/step - loss: 2.1420e-05 - accuracy: 0.1820 - val_loss: 0.1206 - val_accuracy: 0.0429\n",
      "Epoch 760/800\n",
      "59/59 [==============================] - 14s 231ms/step - loss: 2.8851e-05 - accuracy: 0.1623 - val_loss: 0.1241 - val_accuracy: 0.0762\n",
      "Epoch 761/800\n",
      "59/59 [==============================] - 14s 242ms/step - loss: 2.3820e-05 - accuracy: 0.1894 - val_loss: 0.1243 - val_accuracy: 0.0667\n",
      "Epoch 762/800\n",
      "59/59 [==============================] - 15s 250ms/step - loss: 2.2178e-05 - accuracy: 0.1772 - val_loss: 0.1247 - val_accuracy: 0.0619\n",
      "Epoch 763/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 2.1773e-05 - accuracy: 0.1968 - val_loss: 0.1270 - val_accuracy: 0.0762\n",
      "Epoch 764/800\n",
      "59/59 [==============================] - 13s 213ms/step - loss: 2.0713e-05 - accuracy: 0.1899 - val_loss: 0.1248 - val_accuracy: 0.0810\n",
      "Epoch 765/800\n",
      "59/59 [==============================] - 13s 227ms/step - loss: 2.0559e-05 - accuracy: 0.1841 - val_loss: 0.1254 - val_accuracy: 0.0667\n",
      "Epoch 766/800\n",
      "59/59 [==============================] - 13s 223ms/step - loss: 2.1540e-05 - accuracy: 0.1873 - val_loss: 0.1253 - val_accuracy: 0.0667\n",
      "Epoch 767/800\n",
      "59/59 [==============================] - 13s 228ms/step - loss: 2.0510e-05 - accuracy: 0.1873 - val_loss: 0.1233 - val_accuracy: 0.0524\n",
      "Epoch 768/800\n",
      "59/59 [==============================] - 13s 226ms/step - loss: 1.9764e-05 - accuracy: 0.1936 - val_loss: 0.1233 - val_accuracy: 0.0571\n",
      "Epoch 769/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 2.0892e-05 - accuracy: 0.1782 - val_loss: 0.1247 - val_accuracy: 0.0571\n",
      "Epoch 770/800\n",
      "59/59 [==============================] - 12s 200ms/step - loss: 2.1382e-05 - accuracy: 0.1878 - val_loss: 0.1236 - val_accuracy: 0.0429\n",
      "Epoch 771/800\n",
      "59/59 [==============================] - 11s 186ms/step - loss: 2.2895e-05 - accuracy: 0.1777 - val_loss: 0.1229 - val_accuracy: 0.0429\n",
      "Epoch 772/800\n",
      "59/59 [==============================] - 12s 201ms/step - loss: 2.7912e-05 - accuracy: 0.1867 - val_loss: 0.1247 - val_accuracy: 0.0619\n",
      "Epoch 773/800\n",
      "59/59 [==============================] - 12s 204ms/step - loss: 5.0371e-05 - accuracy: 0.1613 - val_loss: 0.1310 - val_accuracy: 0.0762\n",
      "Epoch 774/800\n",
      "59/59 [==============================] - 12s 212ms/step - loss: 3.2618e-05 - accuracy: 0.1719 - val_loss: 0.1276 - val_accuracy: 0.0667\n",
      "Epoch 775/800\n",
      "59/59 [==============================] - 13s 224ms/step - loss: 2.4937e-05 - accuracy: 0.1777 - val_loss: 0.1267 - val_accuracy: 0.0762\n",
      "Epoch 776/800\n",
      "59/59 [==============================] - 14s 240ms/step - loss: 2.2405e-05 - accuracy: 0.1825 - val_loss: 0.1255 - val_accuracy: 0.0810\n",
      "Epoch 777/800\n",
      "59/59 [==============================] - 14s 234ms/step - loss: 2.3816e-05 - accuracy: 0.1979 - val_loss: 0.1268 - val_accuracy: 0.0857\n",
      "Epoch 778/800\n",
      "59/59 [==============================] - 14s 230ms/step - loss: 3.6649e-05 - accuracy: 0.1660 - val_loss: 0.1253 - val_accuracy: 0.0714\n",
      "Epoch 779/800\n",
      "59/59 [==============================] - 13s 216ms/step - loss: 2.5936e-05 - accuracy: 0.1708 - val_loss: 0.1270 - val_accuracy: 0.0714\n",
      "Epoch 780/800\n",
      "59/59 [==============================] - 13s 214ms/step - loss: 2.1684e-05 - accuracy: 0.1926 - val_loss: 0.1260 - val_accuracy: 0.0619\n",
      "Epoch 781/800\n",
      "59/59 [==============================] - 13s 216ms/step - loss: 2.0633e-05 - accuracy: 0.1857 - val_loss: 0.1263 - val_accuracy: 0.0571\n",
      "Epoch 782/800\n",
      "59/59 [==============================] - 13s 215ms/step - loss: 2.1221e-05 - accuracy: 0.1973 - val_loss: 0.1250 - val_accuracy: 0.0571\n",
      "Epoch 783/800\n",
      "59/59 [==============================] - 13s 221ms/step - loss: 2.1559e-05 - accuracy: 0.1878 - val_loss: 0.1246 - val_accuracy: 0.0476\n",
      "Epoch 784/800\n",
      "59/59 [==============================] - 13s 219ms/step - loss: 2.1926e-05 - accuracy: 0.1873 - val_loss: 0.1250 - val_accuracy: 0.0619\n",
      "Epoch 785/800\n",
      "59/59 [==============================] - 14s 245ms/step - loss: 2.0841e-05 - accuracy: 0.1926 - val_loss: 0.1248 - val_accuracy: 0.0476\n",
      "Epoch 786/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 2.2351e-05 - accuracy: 0.1841 - val_loss: 0.1233 - val_accuracy: 0.0571\n",
      "Epoch 787/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 2.2922e-05 - accuracy: 0.1878 - val_loss: 0.1241 - val_accuracy: 0.0571\n",
      "Epoch 788/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 2.1934e-05 - accuracy: 0.1825 - val_loss: 0.1247 - val_accuracy: 0.0619\n",
      "Epoch 789/800\n",
      "59/59 [==============================] - 14s 233ms/step - loss: 2.1010e-05 - accuracy: 0.1920 - val_loss: 0.1255 - val_accuracy: 0.0524\n",
      "Epoch 790/800\n",
      "59/59 [==============================] - 14s 235ms/step - loss: 2.1294e-05 - accuracy: 0.1793 - val_loss: 0.1244 - val_accuracy: 0.0524\n",
      "Epoch 791/800\n",
      "59/59 [==============================] - 14s 232ms/step - loss: 2.0827e-05 - accuracy: 0.1926 - val_loss: 0.1242 - val_accuracy: 0.0571\n",
      "Epoch 792/800\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 2.1919e-05 - accuracy: 0.1910 - val_loss: 0.1244 - val_accuracy: 0.0619\n",
      "Epoch 793/800\n",
      "59/59 [==============================] - 15s 247ms/step - loss: 2.0362e-05 - accuracy: 0.1963 - val_loss: 0.1244 - val_accuracy: 0.0619\n",
      "Epoch 794/800\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 2.1102e-05 - accuracy: 0.1862 - val_loss: 0.1262 - val_accuracy: 0.0571\n",
      "Epoch 795/800\n",
      "59/59 [==============================] - 15s 251ms/step - loss: 2.2565e-05 - accuracy: 0.1920 - val_loss: 0.1257 - val_accuracy: 0.0714\n",
      "Epoch 796/800\n",
      "59/59 [==============================] - 14s 244ms/step - loss: 2.2590e-05 - accuracy: 0.1798 - val_loss: 0.1240 - val_accuracy: 0.0524\n",
      "Epoch 797/800\n",
      "59/59 [==============================] - 15s 246ms/step - loss: 2.1523e-05 - accuracy: 0.1958 - val_loss: 0.1268 - val_accuracy: 0.0571\n",
      "Epoch 798/800\n",
      "59/59 [==============================] - 15s 248ms/step - loss: 2.1450e-05 - accuracy: 0.1942 - val_loss: 0.1247 - val_accuracy: 0.0619\n",
      "Epoch 799/800\n",
      "59/59 [==============================] - 13s 222ms/step - loss: 2.0840e-05 - accuracy: 0.1952 - val_loss: 0.1256 - val_accuracy: 0.0762\n",
      "Epoch 800/800\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 2.0591e-05 - accuracy: 0.1899 - val_loss: 0.1255 - val_accuracy: 0.0571\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(X, y, epochs=800, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-de151261aec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_training_results(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Getting predictions by predicting from the last available X variable\n",
    "yhat = model.predict(X[-1].reshape(1, n_per_in, n_features)).tolist()[0]\n",
    "\n",
    "# Transforming values back to their normal prices\n",
    "yhat = scaler.inverse_transform(np.array(yhat).reshape(-1,1)).tolist()\n",
    "\n",
    "# Getting the actual values from the last available y variable which correspond to its respective X variable\n",
    "actual = scaler.inverse_transform(y[-1].reshape(-1,1))\n",
    "\n",
    "# Printing and plotting those predictions\n",
    "print(\"Predicted Prices:\\n\", yhat)\n",
    "plt.plot(yhat, label='Predicted')\n",
    "\n",
    "# Printing and plotting the actual values\n",
    "print(\"\\nActual Prices:\\n\", actual.tolist())\n",
    "plt.plot(actual.tolist(), label='Actual')\n",
    "\n",
    "plt.title(f\"Predicted vs Actual Closing Prices\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.savefig(\"BTC_validation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting/Forecasting Future ETH Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting off of y because it contains the most recent dates\n",
    "yhat = model.predict(np.array(df.tail(n_per_in)).reshape(1, n_per_in, n_features)).tolist()[0]\n",
    "\n",
    "# Transforming the predicted values back to their original prices\n",
    "yhat = scaler.inverse_transform(np.array(yhat).reshape(-1,1)).tolist()\n",
    "\n",
    "# Creating a DF of the predicted prices\n",
    "preds = pd.DataFrame(yhat, index=pd.date_range(start=df.index[-1], periods=len(yhat), freq=\"D\"), columns=df.columns)\n",
    "\n",
    "# Printing the predicted prices\n",
    "print(preds)\n",
    "\n",
    "# Number of periods back to visualize the actual values\n",
    "pers = 10\n",
    "\n",
    "# Transforming the actual values to their original price\n",
    "actual = pd.DataFrame(scaler.inverse_transform(df[[\"Close\"]].tail(pers)), index=df.Close.tail(pers).index, columns=df.columns).append(preds.head(1))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(actual, label=\"Actual Prices\")\n",
    "plt.plot(preds, label=\"Predicted Prices\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xlabel(\"Dates\")\n",
    "plt.title(f\"Forecasting the next {len(yhat)} days\")\n",
    "plt.legend()\n",
    "plt.savefig(\"BTC_predictions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting off of y because it contains the most recent dates\n",
    "yhat = model.predict(np.array(df.tail(n_per_in)).reshape(1, n_per_in, n_features)).tolist()[0]\n",
    "\n",
    "# Transforming the predicted values back to their original prices\n",
    "yhat = scaler.inverse_transform(np.array(yhat).reshape(-1,1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF of the predicted prices\n",
    "preds = pd.DataFrame(yhat, index=pd.date_range(start=df.index[-1], periods=len(yhat), freq=\"D\"), columns=df.columns)\n",
    "\n",
    "# Printing the predicted prices\n",
    "print(preds)\n",
    "\n",
    "# Number of periods back to visualize the actual values\n",
    "pers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
